# RAGapp.py - é«˜æ€§èƒ½ RAG ã‚·ã‚¹ãƒ†ãƒ  with Streamlit UI

import streamlit as st
import pandas as pd
import os
import datetime
import sys
import logging
import pprint
import json # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨
import torch # GPUæƒ…å ±è¡¨ç¤ºç”¨
from typing import Optional, Tuple, List, Dict, Any # å‹ãƒ’ãƒ³ãƒˆç”¨ã«è¿½åŠ 

# --- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    from config import Config, setup_logging
    # ask_question_ensemble_stream ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from rag_query_utils import initialize_pipeline, ask_question_ensemble_stream
    # utils ã‹ã‚‰å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from utils import format_document_snippet, normalize_str, preprocess_query
    # å·¥å‹™åº—ãƒã‚¹ã‚¿æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from company_master import CompanyMaster
    # è‡ªå‹•å…¥åŠ›æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ  
    from form_auto_fill import display_auto_fill_section
    # calculate_semantic_similarity ã¯ãƒ€ãƒŸãƒ¼ãªã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
    # from utils import calculate_semantic_similarity
except ImportError as e:
    print(f"Import Error in RAGapp.py: {e}", file=sys.stderr)
    try: st.error(f"Import Error: {e}\nå¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"); st.stop()
    except Exception: sys.exit(f"Import Error: {e}")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
try:
    config = Config()
    logger = setup_logging(config, log_filename="streamlit_app_hybrid.log") # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´
    EVALUATION_FILE = "evaluation_log.csv"
except Exception as global_e:
    print(f"Global Setup Error: {global_e}", file=sys.stderr)
    try: st.error(f"Global Setup Error: {global_e}"); st.stop()
    except Exception: sys.exit(f"Global Setup Error: {global_e}")

# --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ– (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã) ---
# ä¸­é–“LLM(ELYZA 7B), Tokenizer, VectorDB, Embedding ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
@st.cache_resource
def load_pipeline_cached(lora_adapter_path: Optional[str] = None) -> tuple:
    """ä¸­é–“LLMã‚’å«ã‚€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    logger.info(f"Attempting to initialize pipeline with LoRA: {lora_adapter_path}")
    try:
        # initialize_pipeline ã¯ vectordb, intermediate_llm, tokenizer, embedding ã‚’è¿”ã™
        pipeline_components = initialize_pipeline(config, logger, lora_adapter_path=lora_adapter_path)
        if not all(comp is not None for comp in pipeline_components): # ã„ãšã‚Œã‹ãŒNoneãªã‚‰å¤±æ•—
            logger.error("Pipeline initialization failed within load_pipeline_cached.")
            # Noneã‚’4ã¤æŒã¤ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™
            return (None,) * 4
        logger.info("Pipeline components initialized successfully.")
        return pipeline_components
    except Exception as e:
        logger.critical(f"Fatal error during pipeline initialization: {e}", exc_info=True)
        return (None,) * 4

def record_evaluation(filename: str, timestamp: str, query: str, final_answer: str, 
                     source_docs: List, answer_evaluation: str, basis_evaluation: str, comment: str) -> bool:
    """è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã™ã‚‹"""
    try:
        filepath = os.path.join(os.path.dirname(__file__), filename)
        file_exists = os.path.isfile(filepath)
        fieldnames = ['timestamp', 'query', 'answer', 'source_docs_summary', 
                     'answer_evaluation', 'basis_evaluation', 'comment']
        
        source_summary = "N/A"
        if source_docs:
            unique_sources = list(set(doc.metadata.get('source', 'N/A') for doc in source_docs))
            source_summary = ", ".join(unique_sources)[:200]
        
        new_eval = pd.DataFrame([{
            'timestamp': timestamp,
            'query': query,
            'answer': final_answer,
            'source_docs_summary': source_summary,
            'answer_evaluation': answer_evaluation,
            'basis_evaluation': basis_evaluation,
            'comment': comment
        }])
        
        new_eval.to_csv(filepath, mode='a', header=not file_exists, index=False, 
                       encoding='utf-8-sig', lineterminator='\n', columns=fieldnames)
        logger.info(f"Evaluation recorded to {filename}")
        return True
        
    except Exception as e:
        logger.error(f"Failed to record evaluation: {e}", exc_info=True)
        return False

# --- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒCSS ---
DARK_THEME_CSS = """
<style>
/* --- åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ« --- */
body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji"; background-color: #0e1117; color: #fafafa; line-height: 1.6; }
.stApp { background-color: #0e1117; }
.main .block-container { max-width: 850px; margin: auto; padding: 1.5rem 2rem 3rem 2rem; }
/* --- è¦‹å‡ºã— --- */
h1 { color: #fafafa; font-size: 2rem; text-align: center; margin-bottom: 1.5rem; font-weight: 600;}
h3 { color: #3b7cff; font-size: 1.3rem; margin-top: 1.5rem; margin-bottom: 0.8rem; border-bottom: 1px solid #333; padding-bottom: 0.3rem;}
h4 { color: #ccc; font-size: 1.1rem; margin-top: 1.2rem; margin-bottom: 0.5rem; }
/* --- ãƒœã‚¿ãƒ³ --- */
div[data-testid="stButton"] > button { background-color: #3b7cff; color: white; padding: 0.5rem 1.2rem; border: none; border-radius: 5px; font-weight: 500; transition: background-color 0.2s ease-in-out, transform 0.1s ease-in-out; cursor: pointer;}
div[data-testid="stButton"] > button:hover { background-color: #5c9bff; transform: translateY(-1px); }
div[data-testid="stButton"] > button:active { background-color: #2a5db0; transform: translateY(0px); }
/* --- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› --- */
div[data-testid="stTextArea"] textarea, div[data-testid="stChatInput"] textarea { border: 1px solid #555; background-color: #262730; color: #fafafa; padding: 0.6rem; border-radius: 5px; font-size: 1rem; width: 100%; box-sizing: border-box; }
div[data-testid="stTextArea"] textarea:focus, div[data-testid="stChatInput"] textarea:focus { border-color: #3b7cff; box-shadow: 0 0 0 2px rgba(59, 124, 255, 0.3); outline: none; }
/* --- æƒ…å ±è¡¨ç¤ºãƒœãƒƒã‚¯ã‚¹ --- */
div[data-testid="stInfo"], div[data-testid="stSuccess"], div[data-testid="stWarning"], div[data-testid="stError"] { border-radius: 5px; padding: 1rem 1.2rem; border: none; background-color: #262730; box-shadow: 0 1px 3px rgba(0,0,0,0.2); margin-bottom: 1rem; color: #fafafa; }
div[data-testid="stInfo"] { border-left: 5px solid #3b7cff; }
div[data-testid="stSuccess"] { border-left: 5px solid #3dd56d; }
div[data-testid="stWarning"] { border-left: 5px solid #ffc107; }
div[data-testid="stError"] { border-left: 5px solid #dc3545; }
/* --- ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ --- */
div[data-testid="stChatMessage"] { background-color: #262730; border: 1px solid #333; border-radius: 8px; margin-bottom: 1rem; padding: 1rem 1.2rem; }
/* --- Expander --- */
div[data-testid="stExpander"] { border: 1px solid #333; border-radius: 5px; background-color: #1c1e24; margin-top: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.2); }
div[data-testid="stExpander"] summary { font-weight: 500; color: #eee; font-size: 1rem; padding: 0.8rem 1rem; cursor: pointer; }
div[data-testid="stExpander"] summary:hover { background-color: #262730; }
div[data-testid="stExpanderDetails"] { padding: 0.5rem 1.5rem 1.5rem 1.5rem; border-top: 1px solid #333; background-color: #262730; }
/* --- ã‚³ãƒ¼ãƒ‰è¡¨ç¤º --- */
div[data-testid="stCodeBlock"] > pre { background-color: #0e1117 !important; border: 1px solid #333 !important; border-radius: 4px !important; padding: 0.8rem !important; color: #eee !important; font-family: 'Courier New', Courier, monospace !important; }
/* --- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ --- */
div[data-testid="stRadio"] label { color: #ccc; margin-right: 0.8rem; }
/* --- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  --- */
div[data-testid="stDataFrame"] { border: 1px solid #333; border-radius: 4px; }
</style>
"""

# --- Streamlit ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    st.set_page_config(page_title="RAG Evaluation (Hybrid)", layout="centered", initial_sidebar_state="collapsed")
    st.markdown(DARK_THEME_CSS, unsafe_allow_html=True)
    st.title("ä½•ã¨ãªãã§ç­”ãˆã‚‹å›")

    # --- LoRA ãƒ‘ã‚¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç† ---
    # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã« config.py ã‹ã‚‰åˆæœŸå€¤ã‚’èª­ã¿è¾¼ã‚€
    if "lora_adapter_path" not in st.session_state:
        st.session_state.lora_adapter_path = config.lora_adapter_path

    # --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰---
    # `load_pipeline_cached` ã‚’å‘¼ã³å‡ºã—ã¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å–å¾—
    # LoRAãƒ‘ã‚¹ãŒå¤‰æ›´ã•ã‚Œã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚¯ãƒªã‚¢ã•ã‚Œå†å®Ÿè¡Œã•ã‚Œã‚‹
    with st.spinner("ğŸš€ ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­... (åˆå›ã¾ãŸã¯LoRAå¤‰æ›´æ™‚)"):
        pipeline_components = load_pipeline_cached(lora_adapter_path=st.session_state.lora_adapter_path)

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ç¢ºèª
    if pipeline_components[0] is None:
        st.error("âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\nğŸ” ãƒ­ã‚°ã‚’ç¢ºèªã—ã€config.py ã‚„ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    vectordb, intermediate_llm, tokenizer, embedding_function = pipeline_components
    logger.info("Pipeline components ready.")
    
    # å·¥å‹™åº—ãƒã‚¹ã‚¿ã®åˆæœŸåŒ–
    if "company_master" not in st.session_state:
        with st.spinner("ğŸ¢ å·¥å‹™åº—ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–ä¸­..."):
            st.session_state.company_master = CompanyMaster(config)
    company_master = st.session_state.company_master

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    ui_state_defaults = {
        "query_history": [],
        "current_query": "",
        "current_answer_stream": None,
        "current_source_docs": [],
        "evaluation_recorded_for_last_answer": False,
        "last_full_answer": "",
        "metadata_filter_str": '{}',
        "variant_answers": [],
        "variant_settings": [
            {
                "k": config.rag_variant_k[i] if i < len(config.rag_variant_k) else 3,
                "temperature": config.temperature,
                "top_p": config.top_p,
                "repetition_penalty": config.repetition_penalty
            } for i in range(3)
        ]
    }
    
    for key, default_value in ui_state_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        st.markdown("##### LoRA è¨­å®š")
        lora_path_input = st.text_input(
            "LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ‘ã‚¹", 
            value=st.session_state.lora_adapter_path or "",
            help="ç©ºæ¬„ã§LoRAç„¡åŠ¹ã€‚å¤‰æ›´å¾Œã¯[å†åˆæœŸåŒ–]å®Ÿè¡Œã€‚"
        )
        
        if st.button("ğŸ”„ å†åˆæœŸåŒ– (LoRAé©ç”¨/è§£é™¤)"):
            new_path = lora_path_input.strip() if lora_path_input else None
            if new_path != st.session_state.lora_adapter_path:
                st.session_state.lora_adapter_path = new_path
                load_pipeline_cached.clear()
                st.success("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å†åˆæœŸåŒ–ã—ã¾ã™...")
                st.rerun()
            else:
                st.info("LoRAãƒ‘ã‚¹ã«å¤‰æ›´ãŒãªã„ãŸã‚ã€å†åˆæœŸåŒ–ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")

        st.divider()
        st.markdown("##### ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š")
        st.caption("å„Variantã®ä¸­é–“ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´")
        # Variantã”ã¨ã®è¨­å®š
        for i in range(len(st.session_state.variant_settings)):
            with st.expander(f"Variant {i+1} è¨­å®š", expanded=(i==0)):
                settings = st.session_state.variant_settings[i]
                settings["k"] = st.number_input(f"æ¤œç´¢æ•° k (V{i+1})", 1, 20, int(settings.get("k", 3)), key=f"k_{i}")
                # ä¸­é–“ç”Ÿæˆç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦è¨­å®š (APIç”¨ã¨ã¯åˆ¥)
                settings["temperature"] = st.slider(f"Temperature (V{i+1})", 0.0, 1.0, float(settings.get("temperature", config.temperature)), 0.05, key=f"temp_{i}")
                settings["top_p"] = st.slider(f"Top_p (V{i+1})", 0.1, 1.0, float(settings.get("top_p", config.top_p)), 0.05, key=f"top_p_{i}")
                settings["repetition_penalty"] = st.slider(f"Rep Penalty (V{i+1})", 1.0, 2.0, float(settings.get("repetition_penalty", config.repetition_penalty)), 0.05, key=f"rep_pen_{i}")

        st.divider()
        st.markdown("##### æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
        filter_input = st.text_area("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (JSON)", st.session_state.metadata_filter_str, height=100, help='ä¾‹: {"type": "ä»•æ§˜"}')
        st.session_state.metadata_filter_str = filter_input # å¤‰æ›´ã‚’å³æ™‚åæ˜  (rerunã¯ä¸è¦)

        st.divider()
        if st.button("ğŸ—‘ï¸ è¡¨ç¤ºã‚¯ãƒªã‚¢"):
            keys_to_clear = [
                "query_history", "current_query", "current_answer_stream",
                "current_source_docs", "evaluation_recorded_for_last_answer",
                "last_full_answer", "variant_answers"
            ]
            for key in keys_to_clear:
                if key in st.session_state:
                    del st.session_state[key]
            st.success("è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
            st.rerun()

        st.divider()
        st.markdown("##### ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        try:
            if torch.cuda.is_available():
                idx = torch.cuda.current_device()
                name = torch.cuda.get_device_name(idx)
                alloc = torch.cuda.memory_allocated(idx) / 1e9
                reserved = torch.cuda.memory_reserved(idx) / 1e9
                st.success(f"ğŸ¯ GPU: {name}\nğŸ“Š Memory: {alloc:.2f}GB / {reserved:.2f}GB")
            else:
                st.info("ğŸ’» Mode: CPU")
        except Exception as gpu_e:
            st.warning(f"âš ï¸ GPUæƒ…å ±å–å¾—å¤±æ•—: {gpu_e}")

    # æ–°è¦ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    st.markdown("### ğŸ“ å·¥å‹™åº—æƒ…å ±å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ")
    
    # ãƒ•ã‚©ãƒ¼ãƒ ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    form_defaults = {
        "form_company_name": "",
        "form_meeting_company": "",
        "form_meeting_person": "",
        "form_tel": "",
        "form_mobile": "",
        "form_email": "",
        "form_outer_wall_strong": "",
        "form_inner_wall_strong": "",
        "form_non_strong_wall": "",
        "form_wall_type": "å¤§å£",
        "form_sub_materials": "æœ‰",
        "form_temporary_brace": "ç„¡",
        "form_foundation_packing": "ç„¡",
        "form_airtight_packing": "ç„¡",
        "form_airtight_range": "",
        "form_steel_post": "ç„¡",
        "form_hardware_install": "ç„¡",
        "form_other_notes": "",
        "company_candidates": [],
        "selected_company": "",
        "show_airtight_range": False,
        "auto_fill_requested": False
    }
    
    for key, default_value in form_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value
    
    with st.form("construction_company_form"):
        st.markdown("#### ğŸ¢ åŸºæœ¬æƒ…å ±")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            company_input = st.text_input(
                "å·¥å‹™åº—å *",
                value=st.session_state.form_company_name,
                placeholder="ä¾‹: æ ªå¼ä¼šç¤¾â—‹â—‹å»ºè¨­",
                help="å·¥å‹™åº—åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚é¡ä¼¼å€™è£œãŒè‡ªå‹•è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
            )
        
        with col2:
            if st.form_submit_button("ğŸ” å·¥å‹™åº—æ¤œç´¢", use_container_width=True):
                if company_input.strip():
                    # å·¥å‹™åº—åè¡¨è¨˜æºã‚Œå¯¾ç­–æ©Ÿèƒ½ã®å®Ÿè¡Œ
                    st.session_state.form_company_name = company_input
                    search_results = company_master.search_companies(company_input, limit=5)
                    
                    if search_results:
                        candidates = []
                        for result in search_results:
                            company_name = result['company']['original_name']
                            candidates.append(f"{company_name}")
                        
                        st.session_state.company_candidates = candidates
                        st.success(f"ğŸ¯ {len(candidates)}ä»¶ã®å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    else:
                        st.session_state.company_candidates = []
                        st.warning("â“ è©²å½“ã™ã‚‹å·¥å‹™åº—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        # å·¥å‹™åº—å€™è£œè¡¨ç¤ºã‚¨ãƒªã‚¢
        if st.session_state.company_candidates:
            st.markdown("**ğŸ¯ å€™è£œé¸æŠ:**")
            selected = st.radio(
                "è©²å½“ã™ã‚‹å·¥å‹™åº—ã‚’é¸æŠã—ã¦ãã ã•ã„",
                options=st.session_state.company_candidates + ["è©²å½“ãªã—ï¼ˆæ–°è¦ç™»éŒ²ï¼‰"],
                key="company_selection"
            )
            if selected != "è©²å½“ãªã—ï¼ˆæ–°è¦ç™»éŒ²ï¼‰":
                st.session_state.selected_company = selected
                
                st.session_state.selected_company = selected
        
        # é€£çµ¡å…ˆæƒ…å ±
        col1, col2 = st.columns(2)
        with col1:
            meeting_company = st.text_input(
                "æ‰“ã¡åˆã‚ã›æ‹…å½“ä¼šç¤¾",
                value=st.session_state.form_meeting_company
            )
            tel = st.text_input(
                "TEL",
                value=st.session_state.form_tel,
                placeholder="ä¾‹: 03-1234-5678"
            )
            email = st.text_input(
                "ãƒ¡ãƒ¼ãƒ«",
                value=st.session_state.form_email,
                placeholder="ä¾‹: contact@example.com"
            )
        
        with col2:
            meeting_person = st.text_input(
                "æ‰“ã¡åˆã‚ã›æ‹…å½“è€…",
                value=st.session_state.form_meeting_person
            )
            mobile = st.text_input(
                "æºå¸¯",
                value=st.session_state.form_mobile,
                placeholder="ä¾‹: 090-1234-5678"
            )
        
        st.divider()
        st.markdown("#### ğŸ§± å£é¢æä»•æ§˜")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            outer_wall = st.text_input(
                "è€åŠ›å£(å¤–éƒ¨)",
                value=st.session_state.form_outer_wall_strong,
                placeholder="ä¾‹: æ§‹é€ ç”¨åˆæ¿ 9mm"
            )
        with col2:
            inner_wall = st.text_input(
                "è€åŠ›å£(å†…éƒ¨)",
                value=st.session_state.form_inner_wall_strong,
                placeholder="ä¾‹: çŸ³è†ãƒœãƒ¼ãƒ‰ 12.5mm"
            )
        with col3:
            non_strong_wall = st.text_input(
                "éè€åŠ›å£",
                value=st.session_state.form_non_strong_wall,
                placeholder="ä¾‹: çŸ³è†ãƒœãƒ¼ãƒ‰ 9.5mm"
            )
        
        st.divider()
        st.markdown("#### ğŸ  å¤–å£ä»•æ§˜")
        
        wall_type = st.radio(
            "å¤–å£ä»•æ§˜",
            options=["å¤§å£", "çœŸå£"],
            index=0 if st.session_state.form_wall_type == "å¤§å£" else 1,
            horizontal=True
        )
        
        st.divider()
        st.markdown("#### ğŸ”§ å‰¯è³‡æ")
        
        sub_materials = st.radio(
            "å‰¯è³‡æã®ä¾›çµ¦",
            options=["æœ‰", "ç„¡"],
            index=0 if st.session_state.form_sub_materials == "æœ‰" else 1,
            horizontal=True
        )
        
        if sub_materials == "æœ‰":
            col1, col2 = st.columns(2)
            with col1:
                temporary_brace = st.radio(
                    "ä»®ç­‹äº¤",
                    options=["æœ‰", "ç„¡"],
                    index=0 if st.session_state.form_temporary_brace == "æœ‰" else 1,
                    horizontal=True
                )
                foundation_packing = st.radio(
                    "åŸºç¤ãƒ‘ãƒƒã‚­ãƒ³",
                    options=["æœ‰", "ç„¡"],
                    index=0 if st.session_state.form_foundation_packing == "æœ‰" else 1,
                    horizontal=True
                )
            
            with col2:
                airtight_packing = st.radio(
                    "æ°—å¯†ãƒ‘ãƒƒã‚­ãƒ³",
                    options=["æœ‰", "ç„¡"],
                    index=0 if st.session_state.form_airtight_packing == "æœ‰" else 1,
                    horizontal=True
                )
                steel_post = st.radio(
                    "é‹¼è£½æŸ",
                    options=["æœ‰", "ç„¡"],
                    index=0 if st.session_state.form_steel_post == "æœ‰" else 1,
                    horizontal=True
                )
            
            # æ°—å¯†ãƒ‘ãƒƒã‚­ãƒ³ãŒã€Œæœ‰ã€ã®å ´åˆã€ç¯„å›²å…¥åŠ›æ¬„ã‚’è¡¨ç¤º
            if airtight_packing == "æœ‰":
                airtight_range = st.text_input(
                    "æ°—å¯†ãƒ‘ãƒƒã‚­ãƒ³ç¯„å›²",
                    value=st.session_state.form_airtight_range,
                    placeholder="é©ç”¨ç¯„å›²ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„"
                )
        
        st.divider()
        st.markdown("#### âš™ï¸ é‡‘ç‰©")
        
        hardware_install = st.radio(
            "é‡‘ç‰©å–ä»˜",
            options=["æœ‰", "ç„¡"],
            index=0 if st.session_state.form_hardware_install == "æœ‰" else 1,
            horizontal=True
        )
        
        st.divider()
        st.markdown("#### ğŸ“‹ ãã®ä»–")
        
        other_notes = st.text_area(
            "ãã®ä»–è¨˜è¼‰äº‹é …",
            value=st.session_state.form_other_notes,
            height=100,
            placeholder="ç‰¹è¨˜äº‹é …ã‚„è£œè¶³æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
        )
        
        st.divider()
        
        # ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡ãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            submitted = st.form_submit_button(
                "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜",
                use_container_width=True,
                type="primary"
            )
        
        if submitted:
            # ãƒ•ã‚©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å‡¦ç†
            form_data = {
                "å·¥å‹™åº—å": company_input,
                "æ‰“ã¡åˆã‚ã›æ‹…å½“ä¼šç¤¾": meeting_company,
                "æ‰“ã¡åˆã‚ã›æ‹…å½“è€…": meeting_person,
                "TEL": tel,
                "æºå¸¯": mobile,
                "ãƒ¡ãƒ¼ãƒ«": email,
                "è€åŠ›å£(å¤–éƒ¨)": outer_wall,
                "è€åŠ›å£(å†…éƒ¨)": inner_wall,
                "éè€åŠ›å£": non_strong_wall,
                "å¤–å£ä»•æ§˜": wall_type,
                "å‰¯è³‡æã®ä¾›çµ¦": sub_materials,
                "ä»®ç­‹äº¤": temporary_brace if sub_materials == "æœ‰" else "-",
                "åŸºç¤ãƒ‘ãƒƒã‚­ãƒ³": foundation_packing if sub_materials == "æœ‰" else "-",
                "æ°—å¯†ãƒ‘ãƒƒã‚­ãƒ³": airtight_packing if sub_materials == "æœ‰" else "-",
                "æ°—å¯†ãƒ‘ãƒƒã‚­ãƒ³ç¯„å›²": airtight_range if sub_materials == "æœ‰" and airtight_packing == "æœ‰" else "-",
                "é‹¼è£½æŸ": steel_post if sub_materials == "æœ‰" else "-",
                "é‡‘ç‰©å–ä»˜": hardware_install,
                "ãã®ä»–è¨˜è¼‰äº‹é …": other_notes
            }
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ›´æ–°
            for key, value in {
                "form_company_name": company_input,
                "form_meeting_company": meeting_company,
                "form_meeting_person": meeting_person,
                "form_tel": tel,
                "form_mobile": mobile,
                "form_email": email,
                "form_outer_wall_strong": outer_wall,
                "form_inner_wall_strong": inner_wall,
                "form_non_strong_wall": non_strong_wall,
                "form_wall_type": wall_type,
                "form_sub_materials": sub_materials,
                "form_temporary_brace": temporary_brace if sub_materials == "æœ‰" else "ç„¡",
                "form_foundation_packing": foundation_packing if sub_materials == "æœ‰" else "ç„¡",
                "form_airtight_packing": airtight_packing if sub_materials == "æœ‰" else "ç„¡",
                "form_airtight_range": airtight_range if sub_materials == "æœ‰" and airtight_packing == "æœ‰" else "",
                "form_steel_post": steel_post if sub_materials == "æœ‰" else "ç„¡",
                "form_hardware_install": hardware_install,
                "form_other_notes": other_notes
            }.items():
                st.session_state[key] = value
            
            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")
            
            # ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
            with st.expander("ğŸ“‹ ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª", expanded=True):
                for key, value in form_data.items():
                    if value and value != "-":
                        st.write(f"**{key}**: {value}")
            
            # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
            import pandas as pd
            import io
            
            df_export = pd.DataFrame([form_data])
            csv_buffer = io.StringIO()
            df_export.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            csv_data = csv_buffer.getvalue()
            
            st.download_button(
                label="ğŸ“„ CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data.encode('utf-8-sig'),
                file_name=f"construction_data_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    
    # ãƒ•ã‚©ãƒ¼ãƒ å¤–ã®è‡ªå‹•å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    display_auto_fill_section(
        company_master, vectordb, intermediate_llm, tokenizer, embedding_function, config
    )
    
    st.divider()
    
    # ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
    st.markdown("### ğŸ’¬ ä¼šè©±å±¥æ­´")
    if not st.session_state.query_history:
        st.info("ğŸ‘‹ è³ªå•ã‚’å…¥åŠ›ã—ã¦ä¼šè©±ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
    else:
        for message in st.session_state.query_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # é€²è¡Œä¸­ã®å›ç­”è¡¨ç¤ºã‚¨ãƒªã‚¢
    streaming_placeholder = st.empty()

    # è³ªå•å…¥åŠ›
    user_query_input = st.chat_input("ğŸ’­ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

    # --- æ–°ã—ã„è³ªå•ãŒå…¥åŠ›ã•ã‚ŒãŸå ´åˆã®å‡¦ç† ---
    if user_query_input:
        st.session_state.current_query = preprocess_query(user_query_input)
        st.session_state.evaluation_recorded_for_last_answer = False
        st.session_state.last_full_answer = ""
        st.session_state.variant_answers = []
        st.session_state.current_source_docs = []
        st.session_state.current_answer_stream = None # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢

        # å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º (é‡è¤‡è¡¨ç¤ºã‚’é˜²ããŸã‚ã€ä¸€æ—¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã€‚ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Œäº†å¾Œã«è¿½åŠ )
        # st.session_state.query_history.append({"role": "user", "content": st.session_state.current_query})
        # with st.chat_message("user"): st.markdown(st.session_state.current_query)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è§£æ
        parsed_metadata_filter = None
        try:
            filter_str = st.session_state.metadata_filter_str.strip()
            if filter_str and filter_str != '{}':
                parsed_metadata_filter = json.loads(filter_str)
                if not isinstance(parsed_metadata_filter, dict):
                    st.warning("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯JSONè¾æ›¸å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", icon="âš ï¸")
                    parsed_metadata_filter = None
                else:
                    logger.info(f"Applying metadata filter: {parsed_metadata_filter}")
            else:
                logger.info("No metadata filter applied.")
        except json.JSONDecodeError:
            st.warning("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚", icon="âš ï¸")
            parsed_metadata_filter = None

        # å›ç­”ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹
        try:
            logger.info(f"Calling ask_question_ensemble_stream with query: {st.session_state.current_query}")
            # <<< CORRECTED: ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‹ã‚‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ¸¡ã™ >>>
            response = ask_question_ensemble_stream(
                vectordb=vectordb,                 # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‹ã‚‰
                intermediate_llm=intermediate_llm, # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‹ã‚‰
                tokenizer=tokenizer,               # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‹ã‚‰
                embedding_function=embedding_function, # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‹ã‚‰
                config=config,
                query=st.session_state.current_query,
                logger=logger,
                metadata_filter=parsed_metadata_filter,
                variant_params=st.session_state.variant_settings # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã•ã‚ŒãŸå€¤
            )
            # <<< END CORRECTED >>>
            st.session_state.current_answer_stream = response.get("result_stream")
            st.session_state.current_source_docs = response.get("source_documents", [])
            st.session_state.variant_answers = response.get("variant_answers", [])
            logger.info("Response object received from ask_question_ensemble_stream.")
            # è³ªå•ã‚’å±¥æ­´ã«è¿½åŠ 
            st.session_state.query_history.append({
                "role": "user", 
                "content": st.session_state.current_query
            })

        except Exception as e:
            logger.error(f"Error during ask_question_ensemble_stream call: {e}", exc_info=True)
            error_msg = f"è³ªå•å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:100]}...\nè¨­å®šã‚„å…¥åŠ›å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            st.error(error_msg)
            st.session_state.current_answer_stream = iter([f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:100]}..."])
            st.session_state.current_source_docs = []
            st.session_state.variant_answers = []
            
            if (not st.session_state.query_history or 
                st.session_state.query_history[-1]['content'] != st.session_state.current_query):
                st.session_state.query_history.append({
                    "role": "user", 
                    "content": st.session_state.current_query
                })

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºå‡¦ç†ã®ãŸã‚ã«å†å®Ÿè¡Œ
        st.rerun()

    # --- å›ç­”ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º ---
    if st.session_state.current_answer_stream:
        with streaming_placeholder.container():
             with st.chat_message("assistant"):
                 answer_placeholder = st.empty() # ã“ã“ã«ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½è¨˜ã—ã¦ã„ã
                 full_response = ""
                 logger.info("Starting answer streaming...")
                 try:
                     for chunk in st.session_state.current_answer_stream:
                          full_response += chunk
                          answer_placeholder.markdown(full_response + "â–Œ") # ã‚«ãƒ¼ã‚½ãƒ«é¢¨ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
                     answer_placeholder.markdown(full_response) # ã‚«ãƒ¼ã‚½ãƒ«ã‚’æ¶ˆã—ã¦æœ€çµ‚çµæœè¡¨ç¤º
                     st.session_state.last_full_answer = full_response # å®Œå…¨ãªå›ç­”ã‚’ä¿å­˜

                     # å›ç­”ã®ã‚³ãƒ”ãƒ¼æ©Ÿèƒ½
                     if full_response:
                         with st.expander("ğŸ“‹ å›ç­”ã‚’ã‚³ãƒ”ãƒ¼", expanded=False):
                             st.code(full_response, language="markdown")
                             st.download_button(
                                 label="ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                 data=full_response,
                                 file_name=f"rag_answer_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                                 mime="text/plain",
                                 key="copy_answer_button",
                                 use_container_width=True
                             )

                     # å±¥æ­´ã¸ã®è¿½åŠ 
                     if (not st.session_state.query_history or 
                         st.session_state.query_history[-1]['content'] != full_response):
                         
                         if (st.session_state.query_history and 
                             st.session_state.query_history[-1]['role'] == 'user'):
                             st.session_state.query_history.append({
                                 "role": "assistant", 
                                 "content": full_response
                             })
                         elif (st.session_state.query_history and 
                               "ã‚¨ãƒ©ãƒ¼" in st.session_state.query_history[-1]['content']):
                             st.session_state.query_history[-1]['content'] = full_response
                     logger.info("Streaming finished.")

                 except Exception as stream_e:
                     logger.error(f"Error during streaming display: {stream_e}", exc_info=True)
                     error_msg = f"å›ç­”è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(stream_e)[:100]}...\nãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€å†åº¦è³ªå•ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚"
                     st.error(error_msg)
                     st.session_state.last_full_answer = f"è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(stream_e)[:100]}..."
                     error_message = st.session_state.last_full_answer
                     
                     if (not st.session_state.query_history or 
                         st.session_state.query_history[-1].get("content") != error_message):
                         if st.session_state.query_history and st.session_state.query_history[-1]['role'] == 'user':
                             st.session_state.query_history.append({
                                 "role": "assistant", 
                                 "content": error_message
                             })
                         elif st.session_state.query_history:
                             st.session_state.query_history[-1]['content'] = error_message

                 finally:
                     st.session_state.current_answer_stream = None
                     st.rerun()

    # --- è©³ç´°æƒ…å ±ã¨variantæ¯”è¼ƒãƒ»è©•ä¾¡ ---
    # last_full_answer ãŒç¢ºå®šã—ãŸã‚‰è¡¨ç¤º
    if st.session_state.last_full_answer:
        with st.expander("è©³ç´°æƒ…å ± (Variantæ¯”è¼ƒãƒ»å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ»è©•ä¾¡)"):

            # Variantæ¯”è¼ƒ
            if st.session_state.variant_answers:
                st.markdown("#### ğŸ”„ Variant æ¯”è¼ƒ")
                for idx, v_ans in enumerate(st.session_state.variant_answers):
                    params = st.session_state.variant_settings[idx]
                    with st.expander(f"ğŸ¯ Variant {idx+1} (k={params['k']}, temp={params['temperature']:.2f})", expanded=False):
                        st.text_area(
                            "Variant Response", 
                            v_ans, 
                            height=150, 
                            disabled=True, 
                            label_visibility="collapsed", 
                            key=f"v_ans_{idx}"
                        )
                st.divider()

            # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
            st.markdown("#### ğŸ“š å‚ç…§ãƒ‡ãƒ¼ã‚¿")
            if st.session_state.current_source_docs:
                st.info(f"ğŸ” é–¢é€£ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯: {len(st.session_state.current_source_docs)} ä»¶")
                
                for i, doc in enumerate(st.session_state.current_source_docs):
                    meta_display = []
                    cols = config.metadata_display_columns
                    score = doc.metadata.get('rerank_score')
                    
                    for col_name in cols:
                        if value := doc.metadata.get(col_name):
                            meta_display.append(f"**{col_name[:4]}**: `{str(value)[:20]}`")
                    
                    if score:
                        meta_display.append(f"**Score**: `{score:.3f}`")
                    
                    with st.expander(f"ğŸ“„ Chunk {i+1} - {' | '.join(meta_display)}", expanded=False):
                        st.text_area(
                            "Document Content",
                            doc.page_content,
                            height=150,
                            disabled=True,
                            label_visibility="collapsed",
                            key=f"src_content_{i}",
                            help="å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹"
                        )
            else:
                st.info("ğŸ” å‚ç…§ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.divider()

            # è©•ä¾¡å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.markdown("#### â­ å›ç­”ã®è©•ä¾¡")
            if not st.session_state.evaluation_recorded_for_last_answer:
                eval_key_suffix = f"_{len(st.session_state.query_history)}"
                
                with st.form(f"evaluation_form_{eval_key_suffix}"):
                    st.markdown("ğŸ” **å›ç­”ã®è³ªã‚’è©•ä¾¡ã—ã¦ãã ã•ã„**")
                    
                    eval_cols = st.columns(2)
                    with eval_cols[0]:
                        ans_opts = ["æœªé¸æŠ", "âœ… å„ªç§€", "ğŸ‘ è‰¯ã„", "ğŸ¤” éƒ¨åˆ†çš„", "âŒ ä¸ååˆ†"]
                        ans_eval = st.radio(
                            "ğŸ’¬ å›ç­”ã®å“è³ª",
                            ans_opts,
                            key=f"eval_ans{eval_key_suffix}",
                            horizontal=False
                        )
                    
                    with eval_cols[1]:
                        basis_opts = ["æœªé¸æŠ", "âœ… é©åˆ‡", "âš ï¸ éƒ¨åˆ†çš„", "âŒ ä¸é©åˆ‡", "ğŸ¤· ä¸æ˜"]
                        bas_eval = st.radio(
                            "ğŸ“„ æ ¹æ‹ ã®é©åˆ‡ã•",
                            basis_opts,
                            key=f"eval_bas{eval_key_suffix}",
                            horizontal=False
                        )
                    
                    cmt = st.text_area(
                        "ğŸ“ ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆä»»æ„ï¼‰",
                        key=f"eval_com{eval_key_suffix}",
                        height=80,
                        placeholder="æ”¹å–„ç‚¹ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å…¥åŠ›..."
                    )
                    
                    submitted = st.form_submit_button("ğŸ’¾ è©•ä¾¡ã‚’è¨˜éŒ²", use_container_width=True)
                    
                    if submitted:
                        if ans_eval != "æœªé¸æŠ" and bas_eval != "æœªé¸æŠ":
                            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                            query = (st.session_state.query_history[-2]['content'] 
                                   if len(st.session_state.query_history) >= 2 else "N/A")
                            
                            success = record_evaluation(
                                EVALUATION_FILE, timestamp, query,
                                st.session_state.last_full_answer,
                                st.session_state.current_source_docs,
                                ans_eval, bas_eval, cmt
                            )
                            
                            if success:
                                st.success("âœ”ï¸ è©•ä¾¡ã‚’è¨˜éŒ²ã—ã¾ã—ãŸï¼")
                                st.session_state.evaluation_recorded_for_last_answer = True
                                st.rerun()
                            else:
                                st.error("âš ï¸ è©•ä¾¡ã®è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        else:
                            st.warning("âš ï¸ å›ç­”ã¨æ ¹æ‹ ã®ä¸¡æ–¹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.success("âœ”ï¸ ã“ã®å›ç­”ã¯æ—¢ã«è©•ä¾¡æ¸ˆã¿ã§ã™ã€‚")
            st.divider()

            # è©•ä¾¡ãƒ­ã‚°ã®è¡¨ç¤º
            st.markdown("#### ğŸ“ˆ è©•ä¾¡ãƒ­ã‚°")
            eval_file_path = os.path.join(os.path.dirname(__file__), EVALUATION_FILE)
            
            @st.cache_data
            def load_evaluation_data(filepath: str) -> Optional[pd.DataFrame]:
                if os.path.exists(filepath):
                    try:
                        return pd.read_csv(filepath)
                    except pd.errors.EmptyDataError:
                        return pd.DataFrame()
                    except Exception as e:
                        logger.error(f"Error loading evaluation log: {e}")
                        return None
                return None
            
            df_eval = load_evaluation_data(eval_file_path)
            
            if df_eval is not None and not df_eval.empty:
                with st.expander(f"ğŸ“‹ æœ€æ–°ã®è©•ä¾¡ãƒ­ã‚° ({len(df_eval)}ä»¶)", expanded=False):
                    display_cols = ['timestamp', 'query', 'answer_evaluation', 'basis_evaluation', 'comment']
                    st.dataframe(
                        df_eval[display_cols].tail(10).reset_index(drop=True),
                        use_container_width=True
                    )
                    
                    @st.cache_data
                    def get_csv_data(df: pd.DataFrame) -> bytes:
                        return df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                    
                    csv_data = get_csv_data(df_eval)
                    st.download_button(
                        label="ğŸ’¾ å…¨è©•ä¾¡ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv_data,
                        file_name=f"evaluation_log_{datetime.datetime.now().strftime('%Y%m%d')}.csv",
                        mime='text/csv',
                        use_container_width=True
                    )
            else:
                st.info("ğŸ“ˆ ã¾ã è©•ä¾¡ãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.critical(f"Application crashed: {e}", exc_info=True)
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}...")
        st.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")