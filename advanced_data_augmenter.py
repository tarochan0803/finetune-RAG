# advanced_data_augmenter.py - é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ 
# ã‚ˆã‚Šå¤šæ§˜ã§å®Ÿç”¨çš„ãªè³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ

import json
import random
import re
from typing import List, Dict, Any, Set
from collections import defaultdict, Counter

class AdvancedDataAugmenter:
    def __init__(self, input_jsonl_path: str):
        self.input_path = input_jsonl_path
        self.original_data = self.load_data()
        self.company_specs = self.analyze_companies()
        self.spec_categories = self.analyze_spec_categories()
        
    def load_data(self) -> List[Dict]:
        """JSONLãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        data = []
        with open(self.input_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
        return data
    
    def analyze_companies(self) -> Dict[str, List[Dict]]:
        """å·¥å‹™åº—åˆ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
        companies = defaultdict(list)
        for item in self.original_data:
            input_text = item.get('input', '')
            if 'æ ªå¼ä¼šç¤¾' in input_text:
                company = input_text.split('ä»£è¡¨æ¡ä»¶è¡¨')[0].strip()
                companies[company].append(item)
        return dict(companies)
    
    def analyze_spec_categories(self) -> Dict[str, Set[str]]:
        """ä»•æ§˜ã‚«ãƒ†ã‚´ãƒªã‚’åˆ†æ"""
        categories = defaultdict(set)
        for item in self.original_data:
            input_text = item.get('input', '')
            output_text = item.get('output', '')
            
            # ã‚«ãƒ†ã‚´ãƒªæŠ½å‡º
            if 'å£é¢æä»•æ§˜' in input_text:
                categories['å£ä»•æ§˜'].add(output_text)
            elif 'è€åŠ›å£ä»•æ§˜' in input_text:
                categories['è€åŠ›å£'].add(output_text)
            elif 'ä»®ç­‹äº¤' in input_text:
                categories['ä»®ç­‹äº¤'].add(output_text)
            elif 'é‹¼è£½æŸ' in input_text:
                categories['é‹¼è£½æŸ'].add(output_text)
                
        return {k: list(v) for k, v in categories.items()}
    
    def generate_comparison_questions(self) -> List[Dict]:
        """æ¯”è¼ƒè³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        # å·¥å‹™åº—é–“æ¯”è¼ƒ
        companies = list(self.company_specs.keys())
        for i in range(min(len(companies), 10)):  # ä¸Šä½10ç¤¾
            for j in range(i + 1, min(len(companies), 10)):
                company_a = companies[i]
                company_b = companies[j]
                
                # å£ä»•æ§˜æ¯”è¼ƒ
                augmented.append({
                    "instruction": f"{company_a}ã¨{company_b}ã®å£ä»•æ§˜ã®é•ã„ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "input": f"æ¯”è¼ƒå¯¾è±¡: {company_a} vs {company_b} | é …ç›®: å£é¢æä»•æ§˜",
                    "output": f"{company_a}ã¨{company_b}ã®å£ä»•æ§˜ã‚’æ¯”è¼ƒã™ã‚‹ã«ã¯ã€ãã‚Œãã‚Œã®ä»£è¡¨æ¡ä»¶è¡¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
                })
                
        return augmented
    
    def generate_conditional_questions(self) -> List[Dict]:
        """æ¡ä»¶ä»˜ãè³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        conditions = [
            "ç‹­å°åœ°ã®å ´åˆ",
            "ç‰¹æ®Šãªæ•·åœ°æ¡ä»¶ã®å ´åˆ", 
            "ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆãŸã„å ´åˆ",
            "é«˜å“è³ªä»•æ§˜ã«ã—ãŸã„å ´åˆ",
            "æ–½å·¥æœŸé–“ã‚’çŸ­ç¸®ã—ãŸã„å ´åˆ"
        ]
        
        for company, specs in list(self.company_specs.items())[:5]:  # ä¸Šä½5ç¤¾
            for condition in conditions:
                augmented.append({
                    "instruction": f"{condition}ã€{company}ã§ã¯ã©ã®ã‚ˆã†ãªä»•æ§˜ã«ãªã‚Šã¾ã™ã‹ï¼Ÿ",
                    "input": f"{company}ã®æ¡ä»¶ä»˜ãä»•æ§˜ | æ¡ä»¶: {condition}",
                    "output": f"{condition}ã®{company}ã®ä»•æ§˜ã«ã¤ã„ã¦ã¯ã€å€‹åˆ¥ã®æ¡ä»¶ã«å¿œã˜ã¦æ¨™æº–ä»•æ§˜ã‹ã‚‰èª¿æ•´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ã¯æ¡ä»¶è¡¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                })
        
        return augmented
    
    def generate_negative_questions(self) -> List[Dict]:
        """å¦å®šå½¢ãƒ»ç¢ºèªè³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        # ä»•æ§˜ç¢ºèªã®å¦å®šå½¢
        negative_patterns = [
            ("å¤§å£ä»•æ§˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿ", "çœŸå£", "ã„ã„ãˆã€çœŸå£ä»•æ§˜ã§ã™ã€‚"),
            ("çœŸå£ä»•æ§˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿ", "å¤§å£", "ã„ã„ãˆã€å¤§å£ä»•æ§˜ã§ã™ã€‚"),
            ("ä»®ç­‹äº¤ã¯ä¸è¦ã§ã™ã‹ï¼Ÿ", "ä»®ç­‹äº¤ã¯æœ‰", "ã„ã„ãˆã€ä»®ç­‹äº¤ã¯å¿…è¦ã§ã™ã€‚"),
            ("é‹¼è£½æŸã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã‹ï¼Ÿ", "é‹¼è£½æŸ", "ä½¿ç”¨çŠ¶æ³ã«ã¤ã„ã¦ã¯æ¡ä»¶è¡¨ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        ]
        
        for company, specs in list(self.company_specs.items())[:3]:
            for question, check_word, answer in negative_patterns:
                augmented.append({
                    "instruction": f"{company}ã¯{question}",
                    "input": f"{company}ã®ä»•æ§˜ç¢ºèª",
                    "output": answer
                })
        
        return augmented
    
    def generate_technical_questions(self) -> List[Dict]:
        """æŠ€è¡“çš„è©³ç´°è³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        technical_aspects = [
            ("æ§‹é€ è¨ˆç®—", "æ§‹é€ è¨ˆç®—ã®æ–¹æ³•ã‚„åŸºæº–ã«ã¤ã„ã¦"),
            ("åŸºç¤è¨­è¨ˆ", "åŸºç¤ã®ç«‹ä¸Šé«˜ã•ã‚„é…ç­‹ã«ã¤ã„ã¦"), 
            ("é‡‘ç‰©ä»•æ§˜", "ä½¿ç”¨ã™ã‚‹é‡‘ç‰©ã®ç¨®é¡ã‚„è¦æ ¼ã«ã¤ã„ã¦"),
            ("ææ–™ç­‰ç´š", "ä½¿ç”¨ã™ã‚‹æœ¨æã®ç­‰ç´šã‚„å“è³ªã«ã¤ã„ã¦"),
            ("æ–½å·¥æ–¹æ³•", "ç‰¹æ®Šãªæ–½å·¥æ–¹æ³•ã‚„æ³¨æ„ç‚¹ã«ã¤ã„ã¦")
        ]
        
        for company in list(self.company_specs.keys())[:3]:
            for aspect, description in technical_aspects:
                augmented.append({
                    "instruction": f"{company}ã®{aspect}ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚",
                    "input": f"{company}ä»£è¡¨æ¡ä»¶è¡¨ | æŠ€è¡“é …ç›®: {aspect}",
                    "output": f"{company}ã®{description}ã¯ä»£è¡¨æ¡ä»¶è¡¨ã®è©³ç´°é …ç›®ã§ç¢ºèªã§ãã¾ã™ã€‚"
                })
        
        return augmented
    
    def generate_process_questions(self) -> List[Dict]:
        """ãƒ—ãƒ­ã‚»ã‚¹ãƒ»æ‰‹é †è³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        process_questions = [
            "è¦‹ç©ã‚‚ã‚Šæ™‚ã®æ³¨æ„ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "è¨­è¨ˆæ™‚ã«ç¢ºèªã™ã¹ãé …ç›®ã¯ä½•ã§ã™ã‹ï¼Ÿ", 
            "ç”Ÿç”£ç®¡ç†ã§ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "ç©ç®—æ™‚ã®æ¨™æº–å˜ä¾¡ã¯ã©ã“ã§ç¢ºèªã§ãã¾ã™ã‹ï¼Ÿ",
            "ç‰¹æ®ŠåŠ å·¥ãŒå¿…è¦ãªå ´åˆã®å¯¾å¿œæ–¹æ³•ã¯ï¼Ÿ"
        ]
        
        for company in list(self.company_specs.keys())[:3]:
            for question in process_questions:
                augmented.append({
                    "instruction": f"{company}ã§{question}",
                    "input": f"{company}ã®æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª",
                    "output": f"{company}ã®è©²å½“é …ç›®ã«ã¤ã„ã¦ã¯ä»£è¡¨æ¡ä»¶è¡¨ã®é–¢é€£ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                })
        
        return augmented
    
    def generate_error_detection_questions(self) -> List[Dict]:
        """ã‚¨ãƒ©ãƒ¼æ¤œå‡ºãƒ»æ¤œè¨¼è³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        error_scenarios = [
            "ä»•æ§˜ãŒæ¡ä»¶è¡¨ã¨ç•°ãªã‚‹å ´åˆã®å¯¾å¿œ",
            "è¨­è¨ˆãƒŸã‚¹ã‚’ç™ºè¦‹ã—ãŸå ´åˆã®æ‰‹é †",
            "ç©ç®—ã‚¨ãƒ©ãƒ¼ã®ç¢ºèªæ–¹æ³•",
            "æ–½å·¥ä¸å…·åˆã®äºˆé˜²ç­–",
            "å“è³ªç®¡ç†ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ"
        ]
        
        for company in list(self.company_specs.keys())[:2]:
            for scenario in error_scenarios:
                augmented.append({
                    "instruction": f"{company}ã§{scenario}ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "input": f"{company}ã®ã‚¨ãƒ©ãƒ¼å¯¾å¿œãƒ»å“è³ªç®¡ç†",
                    "output": f"{scenario}ã«ã¤ã„ã¦ã¯ã€{company}ã®æ¨™æº–æ‰‹é †ã«å¾“ã£ã¦å¯¾å¿œã—ã¦ãã ã•ã„ã€‚è©³ç´°ã¯æ¡ä»¶è¡¨ã‚„ç¤¾å†…è¦å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                })
        
        return augmented
    
    def generate_contextual_questions(self) -> List[Dict]:
        """æ–‡è„ˆç†è§£è³ªå•ã‚’ç”Ÿæˆ"""
        augmented = []
        
        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–‡è„ˆã‚’æŠ½å‡º
        for item in self.original_data[:50]:  # æœ€åˆã®50ä»¶ã‚’ä½¿ç”¨
            original_input = item.get('input', '')
            original_output = item.get('output', '')
            
            if 'æ ªå¼ä¼šç¤¾' in original_input and len(original_output) > 5:
                # ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºç‰ˆ
                augmented.append({
                    "instruction": "ã“ã®å·¥å‹™åº—ã®ä»•æ§˜ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
                    "input": original_input,
                    "output": f"ã“ã®å·¥å‹™åº—ã§ã¯ã€{original_output}ã¨ãªã£ã¦ã„ã¾ã™ã€‚"
                })
                
                # ç°¡æ½”ç‰ˆ
                augmented.append({
                    "instruction": "è¦ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "input": original_input,
                    "output": original_output
                })
        
        return augmented
    
    def save_augmented_data(self, output_path: str):
        """æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        print("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Ÿè¡Œä¸­...")
        
        # å„ç¨®æ‹¡å¼µãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
        comparison_data = self.generate_comparison_questions()
        conditional_data = self.generate_conditional_questions()
        negative_data = self.generate_negative_questions()
        technical_data = self.generate_technical_questions()
        process_data = self.generate_process_questions()
        error_data = self.generate_error_detection_questions()
        contextual_data = self.generate_contextual_questions()
        
        # çµ±è¨ˆæƒ…å ±
        augmentation_stats = {
            "å…ƒãƒ‡ãƒ¼ã‚¿": len(self.original_data),
            "æ¯”è¼ƒè³ªå•": len(comparison_data),
            "æ¡ä»¶ä»˜ãè³ªå•": len(conditional_data),
            "å¦å®šå½¢è³ªå•": len(negative_data),
            "æŠ€è¡“è©³ç´°è³ªå•": len(technical_data),
            "ãƒ—ãƒ­ã‚»ã‚¹è³ªå•": len(process_data),
            "ã‚¨ãƒ©ãƒ¼æ¤œå‡ºè³ªå•": len(error_data),
            "æ–‡è„ˆç†è§£è³ªå•": len(contextual_data)
        }
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        all_data = (
            self.original_data + 
            comparison_data + 
            conditional_data + 
            negative_data + 
            technical_data + 
            process_data + 
            error_data + 
            contextual_data
        )
        
        # ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        random.shuffle(all_data)
        
        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in all_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        # çµ±è¨ˆè¡¨ç¤º
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†ï¼")
        for category, count in augmentation_stats.items():
            print(f"   {category}: {count:,}ä»¶")
        print(f"   åˆè¨ˆ: {len(all_data):,}ä»¶")
        print(f"   ä¿å­˜å…ˆ: {output_path}")
        
        return len(all_data)

def main():
    augmenter = AdvancedDataAugmenter("/home/ncnadmin/my_rag_project/enhanced_training_dataset.jsonl")
    total_samples = augmenter.save_augmented_data("/home/ncnadmin/my_rag_project/premium_training_dataset.jsonl")
    
    print(f"\nğŸ‰ ãƒ—ãƒ¬ãƒŸã‚¢ãƒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆå®Œäº†ï¼")
    print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Š: ã‚ˆã‚Šå¤šæ§˜ãª{total_samples:,}ä»¶ã®è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³")

if __name__ == "__main__":
    main()