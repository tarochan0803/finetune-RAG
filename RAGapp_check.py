# RAGapp_check.py (å¤–éƒ¨DBå‚ç…§ãƒ»æ¤œè¨¼ãƒ•ãƒ­ãƒ¼ç‰ˆ)
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd # QAçµæœè¡¨ç¤ºã§ä½¿ã†å¯èƒ½æ€§
import os
import sys
import logging
import time
import tempfile
import traceback
from typing import List, Dict, Any # å‹ãƒ’ãƒ³ãƒˆã§ä½¿ç”¨

# --- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    # â˜…â˜…â˜… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
    from config_check import Config, setup_logging # ä¿®æ­£ã•ã‚ŒãŸconfigã‚’ä½¿ã†
    from rag_query_utils_check import (
        initialize_embedding,       # EmbeddingåˆæœŸåŒ–
        load_external_chroma_db,    # å¤–éƒ¨DBãƒ­ãƒ¼ãƒ‰é–¢æ•°
        ask_question_single_variant # QAå®Ÿè¡Œé–¢æ•°
    )
    from utils_check import (
        ocr_image_with_gemini, ocr_pdf_with_gemini, # OCRé–¢æ•°
        extract_store_name_with_gemini,             # åº—åæŠ½å‡ºé–¢æ•°
        generate_questions,                         # è³ªå•ç”Ÿæˆé–¢æ•°
        format_document_snippet,                    # ã‚¹ãƒ‹ãƒšãƒƒãƒˆè¡¨ç¤ºé–¢æ•°
    )
    # Chromaã¯rag_query_utils_checkå†…ã§ä½¿ã‚ã‚Œã‚‹ã®ã§ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ä¸è¦ã‹ã‚‚
    # from langchain_chroma import Chroma
    from langchain_core.documents import Document # ã‚½ãƒ¼ã‚¹è¡¨ç¤ºã§å‹ãƒã‚§ãƒƒã‚¯ã«ä½¿ã†å¯èƒ½æ€§

except ImportError as e:
    print(f"Import Error: {e}", file=sys.stderr); detailed_error = traceback.format_exc(); print(detailed_error, file=sys.stderr)
    try: st.error(f"Import Error: {e}\n\nTraceback:\n{detailed_error}\n\nç¢ºèªã—ã¦ãã ã•ã„ã€‚"); st.stop()
    except Exception: sys.exit(f"Import Error: {e}\n{detailed_error}")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
try:
    config = Config()
    logger = setup_logging(config, log_filename="rag_pipeline_check.log") # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åæŒ‡å®š
except Exception as global_e: print(f"Global Setup Error: {global_e}", file=sys.stderr); traceback.print_exc(); sys.exit(f"Global Setup Error: {global_e}")

# --- â˜…â˜…â˜… Embeddingé–¢æ•°ã¨å¤–éƒ¨DBã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰â˜…â˜…â˜… ---
@st.cache_resource
def load_components_cached():
    """Embeddingé–¢æ•°ã¨å¤–éƒ¨Chroma DBã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«1å›ï¼‰"""
    logger.info("Initializing components (Embedding and External DB)...")
    embedding_function = initialize_embedding(config, logger)
    if embedding_function is None:
        logger.critical("Embedding function failed to initialize. Cannot proceed.")
        return None, None # EmbeddingãŒãªã„ã¨DBã‚‚ãƒ­ãƒ¼ãƒ‰ã§ããªã„

    external_db = None
    if not config.use_memory_db: # configã§å¤–éƒ¨DBã‚’ä½¿ã†è¨­å®šã®å ´åˆ
        external_db = load_external_chroma_db(config, embedding_function, logger)
        if external_db is None:
            # å¤–éƒ¨DBã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—ã¯è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ã¨ã™ã‚‹
            logger.critical(f"Failed to load external Chroma DB from '{config.persist_directory}'. Cannot proceed.")
            return None, None # DBãŒãªã„ã¨QAã§ããªã„
        logger.info("External Chroma DB loaded successfully.")
    else:
        # ã“ã®ã‚¢ãƒ—ãƒªã¯å¤–éƒ¨DBå‰æãªã®ã§ã€use_memory_db=True ã¯è¨­å®šãƒŸã‚¹ã¨ã™ã‚‹
        logger.critical("Configuration error: 'use_memory_db' is True, but this application requires an external database. Set use_memory_db to False in config_check.py.")
        return None, None

    logger.info("Essential components (Embedding and External DB) initialized.")
    return embedding_function, external_db

# --- QA ãƒ«ãƒ¼ãƒ—å†…å¾…æ©Ÿæ™‚é–“ å®šæ•° ---
QA_LOOP_DELAY_SECONDS = config.api_call_delay_seconds # configã‹ã‚‰å–å¾—

# --- Streamlit ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    st.set_page_config(page_title="RAG Document Check (External DB)", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“ RAG æ–‡æ›¸å†…å®¹ãƒã‚§ãƒƒã‚¯ AI (å¤–éƒ¨DBæ¤œè¨¼ç‰ˆ)")
    st.caption(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸæ–‡æ›¸ã‚’èª­ã¿å–ã‚Šã€å†…å®¹ã«åŸºã¥ã„ã¦ç”Ÿæˆã—ãŸè³ªå•ã‚’ã€å¤–éƒ¨DB({config.persist_directory})ã«å•ã„åˆã‚ã›ã¦æ¤œè¨¼ã—ã¾ã™ã€‚")

    # --- â˜…â˜…â˜… ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆEmbeddingã¨å¤–éƒ¨DBï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰ â˜…â˜…â˜… ---
    embedding_function, external_vdb = load_components_cached()
    if embedding_function is None or external_vdb is None:
        st.error("ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ (Embeddingã¾ãŸã¯å¤–éƒ¨DB)ã€‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(config_check.py)ã®DBãƒ‘ã‚¹ã‚„ã€DBè‡ªä½“ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        logger.critical("Failed to get embedding_function or external_vdb during startup.")
        st.stop() # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢
    logger.info("Embedding function and external VectorDB are ready.")

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ---
    default_session_state = {
        "uploaded_file_info": None,
        "ocr_text": None,
        "extracted_store_name": None,
        "generated_questions": None,
        "qa_results": [],
        "processing_state": "", # "processing", "done", "error"
        # "current_vdb" ã¯ä¸è¦
    }
    for key, default_value in default_session_state.items():
        if key not in st.session_state: st.session_state[key] = default_value

    # === ã‚µã‚¤ãƒ‰ãƒãƒ¼ ===
    with st.sidebar:
        st.header("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ")
        uploaded_file = st.file_uploader("ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["pdf", "png", "jpg", "jpeg"], key="file_uploader")

        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ãƒªã‚»ãƒƒãƒˆå‡¦ç† ---
        if uploaded_file is not None:
            if st.session_state.uploaded_file_info != uploaded_file.name:
                logger.info(f"New file uploaded: {uploaded_file.name}. Resetting application state.")
                st.session_state.uploaded_file_info = uploaded_file.name
                st.session_state.ocr_text = None
                st.session_state.extracted_store_name = None
                st.session_state.generated_questions = None
                st.session_state.qa_results = []
                st.session_state.processing_state = "processing" # å‡¦ç†é–‹å§‹çŠ¶æ…‹ã¸
                st.rerun() # çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦å†æç”»

        # --- ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆOCRã€è³ªå•ç”Ÿæˆï¼‰ ---
        if st.session_state.processing_state == "processing" and uploaded_file is not None:
            # â˜…â˜…â˜… å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‹ã‚‰DBä½œæˆã‚’å‰Šé™¤ â˜…â˜…â˜…
            with st.spinner(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­ (OCR & è³ªå•ç”Ÿæˆ)..."):
                tmp_file_path = None
                try:
                    # 1. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_file_path = tmp_file.name
                    logger.info(f"Temporary file created: {tmp_file_path}")

                    # 2. OCRå‡¦ç†
                    ocr_start_time = time.time()
                    ocr_text_result = ""
                    file_ext = os.path.splitext(tmp_file_path)[1].lower()
                    if file_ext == ".pdf":
                        ocr_text_result = ocr_pdf_with_gemini(tmp_file_path, config.ocr_dpi, config)
                    elif file_ext in [".png",".jpg",".jpeg"]:
                        ocr_text_result = ocr_image_with_gemini(tmp_file_path, config)
                    else:
                        raise ValueError("Unsupported file type for OCR")

                    if "[OCR Error" in ocr_text_result or not ocr_text_result.strip():
                        raise RuntimeError(f"OCR failed or returned empty: {ocr_text_result}")
                    st.session_state.ocr_text = ocr_text_result
                    logger.info(f"OCR completed in {time.time()-ocr_start_time:.2f}s. Text length: {len(ocr_text_result)}")

                    # 3. æ–½å·¥åº—åæŠ½å‡º (è³ªå•ç”Ÿæˆã®ææ–™ã¨ã—ã¦)
                    extract_start_time = time.time()
                    # OCRãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãªã©ã®è€ƒæ…®ã‚‚å¯èƒ½
                    if len(st.session_state.ocr_text) > 10: # ä¾‹: çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯å‡¦ç†ã—ãªã„
                         extracted_store_name_result = extract_store_name_with_gemini(st.session_state.ocr_text, config)
                         st.session_state.extracted_store_name = extracted_store_name_result
                         logger.info(f"Store name extraction done in {time.time()-extract_start_time:.2f}s. Result: '{extracted_store_name_result}'")
                    else:
                         st.session_state.extracted_store_name = None
                         logger.info("OCR text too short, skipping store name extraction.")


                    # â˜…â˜…â˜… ãƒãƒ£ãƒ³ã‚¯åŒ– ã¨ VectorDBä½œæˆ ã¯è¡Œã‚ãªã„ â˜…â˜…â˜…

                    # 4. è³ªå•ç”Ÿæˆ (OCRãƒ†ã‚­ã‚¹ãƒˆã‚„æŠ½å‡ºæƒ…å ±ã‹ã‚‰)
                    qgen_start_time = time.time()
                    # generate_questions ã«æ¸¡ã™æƒ…å ±ã‚’èª¿æ•´ (ä¾‹: åº—åã ã‘ã§ãªãOCRãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚‚æ¸¡ã™ãªã©)
                    st.session_state.generated_questions = generate_questions(st.session_state.extracted_store_name)
                    if st.session_state.generated_questions:
                         logger.info(f"Question generation done in {time.time()-qgen_start_time:.2f}s. Generated {len(st.session_state.generated_questions)} questions.")
                    else:
                         logger.warning("Question generation resulted in no questions.")
                         # è³ªå•ãŒç”Ÿæˆã•ã‚Œãªã‹ã£ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚‚æ¤œè¨

                    st.session_state.processing_state = "done" # å‡¦ç†å®Œäº†çŠ¶æ…‹ã¸
                    st.success("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šã¨è³ªå•ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

                except Exception as proc_e:
                    logger.error(f"Error during file processing (OCR/Question Gen): {proc_e}", exc_info=True)
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {proc_e}")
                    st.session_state.processing_state = "error" # ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã¸
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    if tmp_file_path and os.path.exists(tmp_file_path):
                        try: os.unlink(tmp_file_path); logger.info("Temporary file deleted.")
                        except Exception as del_e: logger.error(f"Failed to delete temporary file: {del_e}")
                    st.rerun() # ã‚¹ãƒ”ãƒŠãƒ¼ã‚’æ¶ˆã—ã€çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã«å†å®Ÿè¡Œ

        # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ å‡¦ç†çµæœæ¦‚è¦è¡¨ç¤º ---
        if st.session_state.uploaded_file_info:
            st.divider()
            st.markdown(f"**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«:** `{st.session_state.uploaded_file_info}`")
            if st.session_state.processing_state == "done":
                st.success("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: èª­ã¿å–ã‚Šå®Œäº†")
                store_display = st.session_state.extracted_store_name or "(ä¸æ˜)"
                st.markdown(f"**æŠ½å‡ºæ–½å·¥åº—å:** {store_display}")
                if st.session_state.ocr_text:
                     with st.expander("OCRãƒ†ã‚­ã‚¹ãƒˆ(æŠœç²‹)", expanded=False):
                          ocr_preview = format_document_snippet(st.session_state.ocr_text, 300)
                          st.text_area("OCRPreviewSidebar", ocr_preview, height=100, disabled=True, label_visibility="collapsed")
            elif st.session_state.processing_state == "error":
                st.error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: å‡¦ç†ã‚¨ãƒ©ãƒ¼")

        st.divider()
        st.markdown(f"**å‚ç…§DB:** `{config.persist_directory}`")
        # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã¯çœç•¥

    # === ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ===
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("âœ… å†…å®¹ãƒã‚§ãƒƒã‚¯ QA çµæœ (å¤–éƒ¨DBå‚ç…§)")
        if st.session_state.processing_state == "done":
            # â˜…â˜…â˜… QAå®Ÿè¡Œæ™‚ã«å¤–éƒ¨DB (external_vdb) ã‚’æ¸¡ã™ â˜…â˜…â˜…
            if st.session_state.generated_questions and external_vdb:
                if not st.session_state.qa_results: # ã¾ã QAã‚’å®Ÿè¡Œã—ã¦ã„ãªã„å ´åˆ
                    st.info(f"**{len(st.session_state.generated_questions)}** ä»¶ã®ãƒã‚§ãƒƒã‚¯é …ç›®ã«ã¤ã„ã¦ã€å¤–éƒ¨DBã«å¯¾ã—ã¦QAã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
                    if st.button("â–¶ï¸ QA ãƒã‚§ãƒƒã‚¯é–‹å§‹ (å¤–éƒ¨DBæ¤œè¨¼)", type="primary", key="start_qa_button"):
                        qa_start_time = time.time()
                        num_q = len(st.session_state.generated_questions)
                        progress_bar = st.progress(0)
                        temp_results = []

                        for i, q in enumerate(st.session_state.generated_questions):
                            q_num = i + 1
                            logger.info(f"Running QA {q_num}/{num_q} against external DB: {q}")
                            progress_bar.progress(q_num / num_q, text=f"å¤–éƒ¨DBæ¤œè¨¼ä¸­ ({q_num}/{num_q})")
                            answer = "[QA Error]"
                            sources = []
                            response_dict = None

                            try:
                                # â˜…â˜…â˜… ask_question_single_variant ã« external_vdb ã‚’æ¸¡ã™ â˜…â˜…â˜…
                                response_dict = ask_question_single_variant(
                                    vectordb=external_vdb, # ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å¤–éƒ¨DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
                                    embedding_function=embedding_function,
                                    config=config,
                                    query=q,
                                    logger_instance=logger
                                    # metadata_filter ã¯å¿…è¦ãªã‚‰è¿½åŠ 
                                )
                                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
                                if isinstance(response_dict, dict):
                                    answer_stream = response_dict.get("result_stream", iter(["[Error: streamãªã—]"]))
                                    final_answer = "".join(list(answer_stream)) # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’çµåˆ
                                    answer = final_answer if final_answer else "(ç©ºã®å›ç­”)"
                                    sources = response_dict.get("source_documents", [])
                                    logger.info(f"QA Q{q_num} completed.")
                                else:
                                    logger.error(f"QA error Q{q_num}: unexpected response type {type(response_dict)}")
                                    answer = "[QA System Error: Unexpected response type]"
                                    sources = []
                            except Exception as qa_e:
                                logger.error(f"QA error during Q{q_num}: {qa_e}", exc_info=True)
                                answer = f"[QA Execution Error: {type(qa_e).__name__}]"
                                sources = []

                            temp_results.append({"q": q, "a": answer, "sources": sources})

                            # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚ã®å¾…æ©Ÿ
                            logger.debug(f"Waiting {QA_LOOP_DELAY_SECONDS}s after QA for Q{q_num}...")
                            time.sleep(QA_LOOP_DELAY_SECONDS)

                        st.session_state.qa_results = temp_results
                        progress_bar.empty()
                        logger.info(f"External DB QA process completed in {time.time() - qa_start_time:.2f} seconds.")
                        st.success("å¤–éƒ¨DBã¸ã®QAãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                        st.rerun() # çµæœã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†å®Ÿè¡Œ

                # --- QAçµæœè¡¨ç¤º ---
                if st.session_state.qa_results:
                    st.markdown("---")
                    st.markdown(f"**æ¤œè¨¼çµæœ ({len(st.session_state.qa_results)} ä»¶):**")
                    for i, result in enumerate(st.session_state.qa_results):
                        with st.expander(f"Q{i+1}: {result['q']}", expanded=False):
                            st.markdown("**å¤–éƒ¨DBã‹ã‚‰ã®å›ç­”:**")
                            st.info(result['a']) # å›ç­”ã‚’è¡¨ç¤º
                            st.markdown("**é–¢é€£æƒ…å ± (å¤–éƒ¨DBã‚ˆã‚Š):**")
                            if result['sources']:
                                for idx, src_doc in enumerate(result['sources']):
                                    if isinstance(src_doc, Document): # Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ãƒã‚§ãƒƒã‚¯
                                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾— (ã‚­ãƒ¼ã¯å®Ÿéš›ã®DBæ§‹é€ ã«åˆã‚ã›ã‚‹)
                                        source_info = src_doc.metadata.get('source', f'doc_{idx}') # 'source'ã‚­ãƒ¼ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                                        display_text = f"Source: {source_info}\n"
                                        display_text += f"...{format_document_snippet(src_doc.page_content, 200)}..." # ã‚¹ãƒ‹ãƒšãƒƒãƒˆè¡¨ç¤º
                                        st.text_area(
                                            f"source_{i}_{idx}",
                                            display_text,
                                            height=100,
                                            disabled=True,
                                            label_visibility="collapsed"
                                        )
                                    else:
                                         st.warning(f"ç„¡åŠ¹ãªã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼: {type(src_doc)}")
                            else:
                                st.warning("é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    # DataFrameè¡¨ç¤ºã‚„ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã¯ã“ã“ã«å®Ÿè£…å¯èƒ½

            elif not st.session_state.generated_questions:
                st.warning("è³ªå•ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
            elif not external_vdb: # ã“ã‚Œã¯é€šå¸¸ç™ºç”Ÿã—ãªã„ã¯ãšï¼ˆèµ·å‹•æ™‚ã«ãƒã‚§ãƒƒã‚¯ã•ã‚Œã‚‹ãŸã‚ï¼‰
                st.error("å¤–éƒ¨VectorDBãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")

        elif st.session_state.processing_state == "":
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        elif st.session_state.processing_state == "error":
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    with col2: # å³ã‚«ãƒ©ãƒ 
        st.subheader("â„¹ï¸ è£œè¶³æƒ…å ±")
        if st.session_state.uploaded_file_info:
            st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«:** `{st.session_state.uploaded_file_info}`")
            store_display = st.session_state.extracted_store_name or "(ä¸æ˜)"
            st.markdown(f"**æŠ½å‡ºæ–½å·¥åº—å:** {store_display}")

            if st.session_state.processing_state == "done":
                 st.markdown(f"**ç”Ÿæˆè³ªå•æ•°:** {len(st.session_state.generated_questions or [])}")

            # å¤–éƒ¨DBã®æƒ…å ±ã‚’è¡¨ç¤º
            st.markdown("---")
            st.markdown(f"**å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±**")
            st.markdown(f"**ãƒ‘ã‚¹:** `{config.persist_directory}`")
            st.markdown(f"**ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å:** `{config.collection_name}`")
            if external_vdb:
                try:
                    vdb_count = external_vdb._collection.count()
                    st.markdown(f"**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°:** {vdb_count}")
                except Exception as e:
                    logger.warning(f"Could not get external VDB count: {e}")
                    st.markdown("**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°:** (å–å¾—å¤±æ•—)")
            else:
                st.markdown("**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** (æœªãƒ­ãƒ¼ãƒ‰)")
        else:
             st.markdown(f"**å‚ç…§DBãƒ‘ã‚¹:** `{config.persist_directory}`")
             st.markdown(f"**ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å:** `{config.collection_name}`")

        # GPUæƒ…å ±ã¯çœç•¥

if __name__ == "__main__":
    # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ­ã‚°å‡ºåŠ›
    logger.info(f"Starting RAGapp_check (External DB Verification Mode)... App Config: persist_dir='{config.persist_directory}', collection='{config.collection_name}'")
    main()