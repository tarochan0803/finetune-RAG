# RAGapp_micheck.py (ã‚¹ãƒ†ãƒƒãƒ—åˆ†å‰²å¯¾å¿œç‰ˆ)
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import os
import sys
import logging
import time
import tempfile
import traceback
from typing import List, Dict, Any, Optional

# --- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    # config ã¯æœ€åˆã«èª­ã¿è¾¼ã‚€
    from config_micheck import Config, setup_logging
    config = Config() # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã¨ã—ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
    logger = setup_logging(config) # ãƒ­ã‚¬ãƒ¼ã‚‚æ—©æœŸã«è¨­å®š

    from rag_query_utils_micheck import (
        initialize_embedding, load_external_chroma_db, ask_question_single_variant
    )
    from utils_micheck import (
        ocr_image_with_gemini, ocr_pdf_with_gemini,
        read_estimate_csv,
        extract_moushikomi_details_rule_based,
        check_detail_rules_with_rag,
        compare_rag_and_moushikomi,
        generate_questions_for_spec,
        format_document_snippet,
        extract_store_name_with_gemini,
        extract_wall_spec_from_text # è£œåŠ©çš„ã«ä½¿ç”¨
    )
    from langchain_core.documents import Document

except ImportError as e:
    # StreamlitãŒèµ·å‹•ã™ã‚‹å‰ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã«ã‚‚å‡ºã™
    print(f"Import Error: {e}", file=sys.stderr)
    detailed_error = traceback.format_exc()
    print(detailed_error, file=sys.stderr)
    # Streamlitèµ·å‹•å¾Œã§ã‚ã‚Œã° st.error ã‚’ä½¿ã„ãŸã„ãŒã€ã“ã“ã§ã¯ sys.exit ã™ã‚‹
    sys.exit(f"Import Error: Required module not found. Check installation and paths.\nError: {e}\n{detailed_error}")
except Exception as global_e:
    print(f"Global Setup Error: {global_e}", file=sys.stderr)
    traceback.print_exc(file=sys.stderr)
    sys.exit(f"Global Setup Error: {global_e}")


# --- Embedding/DBåˆæœŸåŒ– (ã‚­ãƒ£ãƒƒã‚·ãƒ¥) ---
@st.cache_resource
def load_components_cached():
    """Embeddingé–¢æ•°ã¨å¤–éƒ¨Chroma DBã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãƒ­ãƒ¼ãƒ‰"""
    logger.info("Initializing components (Embedding and External DB)...")
    embedding_function = initialize_embedding(config, logger)
    if embedding_function is None:
        logger.critical("Embedding initialization failed.")
        st.error("Embeddingãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None, None

    external_db = None
    if not config.use_memory_db:
        external_db = load_external_chroma_db(config, embedding_function, logger)
        if external_db is None:
            logger.critical(f"Failed to load external DB from {config.persist_directory}.")
            st.error(f"å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹({config.persist_directory})ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‘ã‚¹ã‚„è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return embedding_function, None # Embeddingã¯æˆåŠŸã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§è¿”ã™
        logger.info("External Chroma DB loaded successfully.")
    else:
        # ã“ã®ã‚¢ãƒ—ãƒªã§ã¯å¤–éƒ¨DBãŒå¿…é ˆãªã®ã§ã‚¨ãƒ©ãƒ¼ã¨ã™ã‚‹
        logger.critical("Configuration error: use_memory_db is True, but external DB is required.")
        st.error("è¨­å®šã‚¨ãƒ©ãƒ¼: ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå¿…è¦ã§ã™ (use_memory_db=False)ã€‚")
        return embedding_function, None

    logger.info("Essential components (Embedding and DB) initialized.")
    return embedding_function, external_db


# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ– ---
def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å¤‰æ•°ã‚’åˆæœŸåŒ–"""
    default_values = {
        # ãƒ•ã‚¡ã‚¤ãƒ«é–¢é€£
        "uploaded_moushikomi": None,
        "uploaded_estimate_csv": None,
        "moushikomi_file_name": None,
        "estimate_csv_file_name": None,
        # ã‚¹ãƒ†ãƒƒãƒ—ç®¡ç†
        "current_step": 0, # 0: åˆæœŸ, 1: ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼æ¸ˆ, 2: ç”³é€/RAGæ¯”è¼ƒæ¸ˆ, 3: è¦‹ç©ãƒã‚§ãƒƒã‚¯æ¸ˆ
        # ã‚¹ãƒ†ãƒƒãƒ—1ã®çµæœ
        "moushikomi_ocr_text": None,
        "moushikomi_details": {}, # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æŠ½å‡ºçµæœ
        "store_name": None,
        "estimate_dataframe": None,
        # ã‚¹ãƒ†ãƒƒãƒ—2ã®çµæœ
        "generated_questions": [],
        "rag_qa_results": [],
        "comparison_discrepancies": [], # ç”³é€ vs RAGæ¯”è¼ƒçµæœ
        # ã‚¹ãƒ†ãƒƒãƒ—3ã®çµæœ
        "detail_check_violations": [], # è¦‹ç© vs ä»•æ§˜ãƒã‚§ãƒƒã‚¯çµæœ
        # ãã®ä»–
        "error_message": None,
        "processing": False, # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
        "temp_file_paths": set(), # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
    }
    for key, default_value in default_values.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

# --- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† ---
def add_temp_file_path(path: str):
    if path:
        st.session_state.temp_file_paths.add(path)
        logger.debug(f"Added temp file path: {path}")

def cleanup_temp_files():
    paths_to_remove = set(st.session_state.temp_file_paths)
    if not paths_to_remove:
        logger.debug("No temporary files to clean up.")
        return
    logger.debug(f"Attempting to clean up {len(paths_to_remove)} temp files: {paths_to_remove}")
    cleaned_paths = set()
    for path in paths_to_remove:
        try:
            if path and os.path.exists(path):
                os.unlink(path)
                logger.info(f"Temp file deleted: {path}")
            cleaned_paths.add(path)
        except Exception as e:
            logger.error(f"Failed to delete temp file {path}: {e}")
            # å‰Šé™¤ã«å¤±æ•—ã—ã¦ã‚‚ãƒªã‚¹ãƒˆã‹ã‚‰ã¯æ¶ˆã™ï¼ˆå†è©¦è¡Œã—ãªã„ï¼‰
            cleaned_paths.add(path)
    st.session_state.temp_file_paths -= cleaned_paths
    logger.debug(f"Temp files remaining: {st.session_state.temp_file_paths}")


# --- ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œé–¢æ•° ---

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨åŸºæœ¬æƒ…å ±æŠ½å‡º
def run_step1_load_and_extract():
    """ç”³ã—é€ã‚Šæ›¸OCRã€åŸºæœ¬æƒ…å ±æŠ½å‡ºã€CSVèª­ã¿è¾¼ã¿ã‚’å®Ÿè¡Œ"""
    st.session_state.processing = True
    st.session_state.error_message = None
    # å‰å›ã®çµæœã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚¹ãƒ†ãƒƒãƒ—1é–¢é€£ï¼‰
    st.session_state.moushikomi_ocr_text = None
    st.session_state.moushikomi_details = {}
    st.session_state.store_name = None
    st.session_state.estimate_dataframe = None
    st.session_state.current_step = 0 # åˆæœŸçŠ¶æ…‹ã«æˆ»ã™

    moushikomi_file = st.session_state.get("uploaded_moushikomi")
    estimate_csv_file = st.session_state.get("uploaded_estimate_csv")

    if not moushikomi_file or not estimate_csv_file:
        st.session_state.error_message = "ç”³ã—é€ã‚Šæ›¸ã¨è¦‹ç©æ˜ç´°CSVã®ä¸¡æ–¹ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        st.session_state.processing = False
        logger.error("Step 1 Error: Files not uploaded.")
        st.rerun()
        return

    progress_bar = st.progress(0.0, text="ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨åŸºæœ¬æƒ…å ±æŠ½å‡ºã‚’é–‹å§‹...")
    moushikomi_temp_path = None

    try:
        # 1-1. ç”³ã—é€ã‚Šæ›¸å‡¦ç† (OCRã¨ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æŠ½å‡º)
        progress_bar.progress(0.1, text="ç”³ã—é€ã‚Šæ›¸ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        logger.info(f"Step 1: Processing Moushikomi file: {moushikomi_file.name}")
        st.session_state.moushikomi_file_name = moushikomi_file.name
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(moushikomi_file.name)[1]) as tmp_file:
            tmp_file.write(moushikomi_file.getvalue())
            moushikomi_temp_path = tmp_file.name
            add_temp_file_path(moushikomi_temp_path) # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¨˜éŒ²
        logger.info(f"Moushikomi temp file created: {moushikomi_temp_path}")

        progress_bar.progress(0.2, text="ç”³ã—é€ã‚Šæ›¸ã®OCRã‚’å®Ÿè¡Œä¸­ (Gemini)...")
        ocr_text = None
        if moushikomi_file.type == "application/pdf":
            ocr_text = ocr_pdf_with_gemini(moushikomi_temp_path, config)
        elif moushikomi_file.type in ["image/png", "image/jpeg", "image/webp", "image/heic", "image/heif"]:
             ocr_text = ocr_image_with_gemini(moushikomi_temp_path, config)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ç”³ã—é€ã‚Šæ›¸ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {moushikomi_file.type}")

        if not ocr_text or "[OCR Error" in ocr_text:
             raise RuntimeError(f"ç”³ã—é€ã‚Šæ›¸ã®OCRã«å¤±æ•—ã—ã¾ã—ãŸ: {ocr_text}")
        st.session_state.moushikomi_ocr_text = ocr_text
        logger.info(f"Moushikomi OCR completed. Text length: {len(ocr_text)}")

        progress_bar.progress(0.4, text="ç”³ã—é€ã‚Šæ›¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºä¸­ (Gemini & Rule)...")
        # å·¥å‹™åº—åæŠ½å‡º (Gemini)
        store_name = extract_store_name_with_gemini(ocr_text, config)
        st.session_state.store_name = store_name if store_name and "[Error" not in store_name else "æŠ½å‡ºå¤±æ•—"
        logger.info(f"Store name extracted: {st.session_state.store_name}")
        if st.session_state.store_name == "æŠ½å‡ºå¤±æ•—":
            st.warning("å·¥å‹™åº—åã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚RAGã«ã‚ˆã‚‹ä»•æ§˜ç¢ºèªã®ç²¾åº¦ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        # è©³ç´°æƒ…å ±æŠ½å‡º (ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹)
        moushikomi_details = extract_moushikomi_details_rule_based(ocr_text)
        st.session_state.moushikomi_details = moushikomi_details
        logger.info(f"Rule-based details extracted: {moushikomi_details}")

        progress_bar.progress(0.6, text="è¦‹ç©æ˜ç´°CSVã‚’èª­ã¿è¾¼ã¿ä¸­...")
        logger.info(f"Step 1: Processing Estimate CSV file: {estimate_csv_file.name}")
        st.session_state.estimate_csv_file_name = estimate_csv_file.name
        # CSVèª­ã¿è¾¼ã¿ (utils_micheckã®é–¢æ•°ã‚’ä½¿ç”¨)
        df = read_estimate_csv(estimate_csv_file, config)
        if df is None:
             raise RuntimeError("è¦‹ç©æ˜ç´°CSVã®èª­ã¿è¾¼ã¿ã¾ãŸã¯æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        st.session_state.estimate_dataframe = df
        logger.info(f"Estimate CSV loaded successfully. Shape: {df.shape}")

        progress_bar.progress(1.0, text="ã‚¹ãƒ†ãƒƒãƒ—1: å®Œäº†ï¼")
        st.session_state.current_step = 1 # ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†
        logger.info("Step 1 completed successfully.")
        time.sleep(0.5) # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºç”¨

    except Exception as e:
        logger.error(f"Error during Step 1: {e}", exc_info=True)
        st.session_state.error_message = f"ã‚¹ãƒ†ãƒƒãƒ—1ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}"
        st.session_state.current_step = 0 # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ãƒ†ãƒƒãƒ—ã‚’æˆ»ã™
    finally:
        progress_bar.empty()
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯æœ€å¾Œï¼ˆå…¨ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†å¾Œã‹ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ï¼‰ã«æ¶ˆã™ã®ã§ã€ã“ã“ã§ã¯æ¶ˆã•ãªã„
        st.session_state.processing = False
        st.rerun() # ç”»é¢æ›´æ–°

# ã‚¹ãƒ†ãƒƒãƒ—2: ç”³ã—é€ã‚Šæ›¸ã¨æ¨™æº–ä»•æ§˜ï¼ˆDBï¼‰ã®æ•´åˆæ€§ç¢ºèª
def run_step2_check_moushikomi_vs_rag(embedding_function, external_vdb):
    """RAGã‚’å®Ÿè¡Œã—ã€ç”³ã—é€ã‚Šæ›¸ã®æƒ…å ±ã¨æ¯”è¼ƒ"""
    st.session_state.processing = True
    st.session_state.error_message = None
    # å‰å›ã®çµæœã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2é–¢é€£ï¼‰
    st.session_state.generated_questions = []
    st.session_state.rag_qa_results = []
    st.session_state.comparison_discrepancies = []
    st.session_state.current_step = 1 # ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†çŠ¶æ…‹ã«æˆ»ã™

    store_name = st.session_state.get("store_name")
    moushikomi_details = st.session_state.get("moushikomi_details", {})

    if not store_name or store_name == "æŠ½å‡ºå¤±æ•—":
        st.warning("å·¥å‹™åº—åãŒä¸æ˜ãªãŸã‚ã€RAGã«ã‚ˆã‚‹æ¨™æº–ä»•æ§˜ç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        st.session_state.current_step = 2 # RAGã‚¹ã‚­ãƒƒãƒ—ã§ã‚‚ã‚¹ãƒ†ãƒƒãƒ—2ã¯å®Œäº†æ‰±ã„
        st.session_state.processing = False
        st.rerun()
        return
    if not external_vdb:
        st.session_state.error_message = "å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚RAGã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚"
        st.session_state.processing = False
        logger.error("Step 2 Error: External VDB not loaded.")
        st.rerun()
        return

    progress_bar = st.progress(0.0, text="ã‚¹ãƒ†ãƒƒãƒ—2: RAGã«ã‚ˆã‚‹æ¨™æº–ä»•æ§˜ç¢ºèªã‚’é–‹å§‹...")

    try:
        # 2-1. RAGè³ªå•ç”Ÿæˆ
        progress_bar.progress(0.1, text="æ¨™æº–ä»•æ§˜ç¢ºèªã®ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆä¸­...")
        questions = generate_questions_for_spec(store_name, config)
        st.session_state.generated_questions = questions
        num_q = len(questions)
        logger.info(f"Generated {num_q} questions for RAG (Store: {store_name}).")

        # 2-2. RAGå®Ÿè¡Œ
        temp_qa_results = []
        if questions:
            progress_bar.progress(0.2, text=f"RAGã‚’å®Ÿè¡Œä¸­ (0/{num_q})...")
            for i, q in enumerate(questions):
                q_num = i + 1
                logger.info(f"Running RAG QA {q_num}/{num_q}: {q}")
                # é€²æ—è¨ˆç®— (0.2ã‹ã‚‰0.8ã¾ã§ã‚’ä½¿ç”¨)
                progress_value = 0.2 + (0.6 * (q_num / num_q))
                progress_bar.progress(progress_value, text=f"RAGã‚’å®Ÿè¡Œä¸­ ({q_num}/{num_q})")
                try:
                    # ask_question_single_variant ã‚’ä½¿ç”¨
                    response_dict = ask_question_single_variant(
                        external_vdb, embedding_function, config, q, logger
                    )
                    # result_stream ã¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ãªã®ã§ãƒªã‚¹ãƒˆåŒ–ã—ã¦çµåˆ
                    answer = "".join(list(response_dict.get("result_stream", iter(["[Error: No stream]"]))))
                    sources = response_dict.get("source_documents", [])
                    temp_qa_results.append({"q": q, "a": answer, "sources": sources})
                except Exception as rag_e:
                    logger.error(f"Error during RAG QA for question '{q}': {rag_e}", exc_info=True)
                    temp_qa_results.append({"q": q, "a": f"[RAG Error: {type(rag_e).__name__}]", "sources": []})
            st.session_state.rag_qa_results = temp_qa_results
            logger.info("RAG QA finished.")
        else:
            logger.warning("No questions generated for RAG. Skipping RAG execution.")
            progress_bar.progress(0.8, text="RAGè³ªå•ãŒãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        # 2-3. ç”³ã—é€ã‚Šæ›¸(ãƒ«ãƒ¼ãƒ«æŠ½å‡ºçµæœ) vs RAGæ¯”è¼ƒ
        progress_bar.progress(0.9, text="ç”³ã—é€ã‚Šæ›¸ã®æƒ…å ±ã¨RAGã®çµæœã‚’æ¯”è¼ƒä¸­...")
        discrepancies = compare_rag_and_moushikomi(
            st.session_state.rag_qa_results,
            moushikomi_details, # ã‚¹ãƒ†ãƒƒãƒ—1ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æŠ½å‡ºçµæœ
            config
        )
        st.session_state.comparison_discrepancies = discrepancies
        logger.info(f"Comparison between Moushikomi (Rule) and RAG finished. Found {len(discrepancies)} discrepancies.")

        progress_bar.progress(1.0, text="ã‚¹ãƒ†ãƒƒãƒ—2: å®Œäº†ï¼")
        st.session_state.current_step = 2 # ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†
        logger.info("Step 2 completed successfully.")
        time.sleep(0.5)

    except Exception as e:
        logger.error(f"Error during Step 2: {e}", exc_info=True)
        st.session_state.error_message = f"ã‚¹ãƒ†ãƒƒãƒ—2ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}"
        st.session_state.current_step = 1 # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†çŠ¶æ…‹ã«æˆ»ã™
    finally:
        progress_bar.empty()
        st.session_state.processing = False
        st.rerun()

# ã‚¹ãƒ†ãƒƒãƒ—3: è¦‹ç©æ˜ç´°ã¨ä»•æ§˜ã®æ•´åˆæ€§ç¢ºèª
def run_step3_check_estimate_vs_spec():
    """è¦‹ç©æ˜ç´°ã¨ï¼ˆç”³ã—é€ã‚Šæ›¸ï¼‹RAGï¼‰ä»•æ§˜ã‚’æ¯”è¼ƒ"""
    st.session_state.processing = True
    st.session_state.error_message = None
    # å‰å›ã®çµæœã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3é–¢é€£ï¼‰
    st.session_state.detail_check_violations = []
    st.session_state.current_step = 2 # ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†çŠ¶æ…‹ã«æˆ»ã™

    df = st.session_state.get("estimate_dataframe")
    rag_results = st.session_state.get("rag_qa_results", [])
    moushikomi_details = st.session_state.get("moushikomi_details", {})

    if df is None:
        st.session_state.error_message = "è¦‹ç©æ˜ç´°ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—1ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        st.session_state.processing = False
        logger.error("Step 3 Error: Estimate DataFrame not found.")
        st.rerun()
        return
    # RAGçµæœãŒãªãã¦ã‚‚ãƒã‚§ãƒƒã‚¯ã¯å®Ÿè¡Œå¯èƒ½ï¼ˆRAGç”±æ¥ã®ãƒã‚§ãƒƒã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ï¼‰

    progress_bar = st.progress(0.0, text="ã‚¹ãƒ†ãƒƒãƒ—3: è¦‹ç©æ˜ç´°ã¨ä»•æ§˜ã®æ•´åˆæ€§ç¢ºèªã‚’é–‹å§‹...")

    try:
        # check_detail_rules_with_rag ã‚’ä½¿ç”¨
        progress_bar.progress(0.2, text="è¦‹ç©æ˜ç´°ãƒ‡ãƒ¼ã‚¿ã¨ä»•æ§˜æƒ…å ±ã‚’ç…§åˆä¸­...")
        violations = check_detail_rules_with_rag(
            df,
            rag_results,
            moushikomi_details, # ã‚¹ãƒ†ãƒƒãƒ—1ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æŠ½å‡ºçµæœã‚‚æ¸¡ã™
            config
        )
        st.session_state.detail_check_violations = violations
        logger.info(f"Check between CSV details and specifications finished. Found {len(violations)} violations.")

        progress_bar.progress(1.0, text="ã‚¹ãƒ†ãƒƒãƒ—3: å®Œäº†ï¼")
        st.session_state.current_step = 3 # ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†
        logger.info("Step 3 completed successfully.")
        time.sleep(0.5)

    except Exception as e:
        logger.error(f"Error during Step 3: {e}", exc_info=True)
        st.session_state.error_message = f"ã‚¹ãƒ†ãƒƒãƒ—3ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}"
        st.session_state.current_step = 2 # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†çŠ¶æ…‹ã«æˆ»ã™
    finally:
        progress_bar.empty()
        st.session_state.processing = False
        st.rerun()

# --- Streamlit UI ---
def main():
    st.set_page_config(page_title="MiCheck Step-by-Step", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“„ MiCheck: ç”³ã—é€ã‚Šæ›¸ & è¦‹ç©æ˜ç´° æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  (ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œç‰ˆ)")
    st.caption(f"å‚ç…§DB: {config.persist_directory} | Collection: {config.collection_name}")

    initialize_session_state()

    # --- ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰ ---
    embedding_function, external_vdb = load_components_cached()
    # Embeddingã‹DBã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã—ã¦åœæ­¢
    if embedding_function is None:
        st.error("Embeddingãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚")
        st.stop()
    if external_vdb is None and not config.use_memory_db:
         st.error(f"å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ({config.persist_directory}) ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚")
         st.stop()

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
    with st.sidebar:
        st.header("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        # ç”³ã—é€ã‚Šæ›¸
        uploaded_m_file = st.file_uploader(
            "1. ç”³ã—é€ã‚Šæ›¸ (PDF/Image)",
            type=["pdf", "png", "jpg", "jpeg", "webp", "heic", "heif"],
            key="moushikomi_uploader",
            help="å¯¾å¿œå½¢å¼: PDF, PNG, JPG, WEBP, HEIC, HEIF"
        )
        if uploaded_m_file is not None and st.session_state.uploaded_moushikomi != uploaded_m_file:
            st.session_state.uploaded_moushikomi = uploaded_m_file
            st.session_state.moushikomi_file_name = uploaded_m_file.name
            st.session_state.current_step = 0 # ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ã¯ãƒªã‚»ãƒƒãƒˆ
            logger.debug(f"Moushikomi file uploaded: {uploaded_m_file.name}")
            st.rerun()
        elif uploaded_m_file is None and st.session_state.uploaded_moushikomi is not None:
             st.session_state.uploaded_moushikomi = None
             st.session_state.moushikomi_file_name = None
             st.session_state.current_step = 0
             logger.debug("Moushikomi file removed.")
             st.rerun()

        # è¦‹ç©æ˜ç´°CSV
        uploaded_e_file = st.file_uploader(
            "2. è¦‹ç©æ˜ç´° CSV",
            type="csv",
            key="estimate_csv_uploader",
            help="å¯¾å¿œå½¢å¼: CSV (UTF-8 or Shift-JIS)"
        )
        if uploaded_e_file is not None and st.session_state.uploaded_estimate_csv != uploaded_e_file:
            st.session_state.uploaded_estimate_csv = uploaded_e_file
            st.session_state.estimate_csv_file_name = uploaded_e_file.name
            st.session_state.current_step = 0
            logger.debug(f"Estimate CSV file uploaded: {uploaded_e_file.name}")
            st.rerun()
        elif uploaded_e_file is None and st.session_state.uploaded_estimate_csv is not None:
             st.session_state.uploaded_estimate_csv = None
             st.session_state.estimate_csv_file_name = None
             st.session_state.current_step = 0
             logger.debug("Estimate CSV file removed.")
             st.rerun()

        st.divider()

        # --- ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
        st.header("âš™ï¸ å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—")
        files_ready = st.session_state.uploaded_moushikomi is not None and \
                      st.session_state.uploaded_estimate_csv is not None
        processing_now = st.session_state.processing

        # ã‚¹ãƒ†ãƒƒãƒ—1ãƒœã‚¿ãƒ³
        st.button(
            "â–¶ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: èª­è¾¼ï¼†åŸºæœ¬æƒ…å ±æŠ½å‡º",
            key="run_step1_button",
            on_click=run_step1_load_and_extract,
            disabled=not files_ready or processing_now or st.session_state.current_step > 0, # ãƒ•ã‚¡ã‚¤ãƒ«æœªé¸æŠã€å‡¦ç†ä¸­ã€å®Œäº†æ¸ˆãªã‚‰éæ´»æ€§
            use_container_width=True,
            type="primary" if files_ready and st.session_state.current_step == 0 else "secondary"
        )

        # ã‚¹ãƒ†ãƒƒãƒ—2ãƒœã‚¿ãƒ³
        st.button(
            "â–¶ï¸ ã‚¹ãƒ†ãƒƒãƒ—2: ç”³é€/RAGæ•´åˆæ€§ç¢ºèª",
            key="run_step2_button",
            on_click=run_step2_check_moushikomi_vs_rag,
            args=(embedding_function, external_vdb), # å¼•æ•°ã‚’æ¸¡ã™
            disabled=st.session_state.current_step < 1 or processing_now or st.session_state.current_step > 1, # Step1æœªå®Œäº†ã€å‡¦ç†ä¸­ã€å®Œäº†æ¸ˆãªã‚‰éæ´»æ€§
            use_container_width=True,
            type="primary" if st.session_state.current_step == 1 else "secondary"
        )

        # ã‚¹ãƒ†ãƒƒãƒ—3ãƒœã‚¿ãƒ³
        st.button(
            "â–¶ï¸ ã‚¹ãƒ†ãƒƒãƒ—3: è¦‹ç©æ•´åˆæ€§ç¢ºèª",
            key="run_step3_button",
            on_click=run_step3_check_estimate_vs_spec,
            disabled=st.session_state.current_step < 2 or processing_now or st.session_state.current_step > 2, # Step2æœªå®Œäº†ã€å‡¦ç†ä¸­ã€å®Œäº†æ¸ˆãªã‚‰éæ´»æ€§
            use_container_width=True,
            type="primary" if st.session_state.current_step == 2 else "secondary"
        )

        if processing_now:
            st.warning("å‡¦ç†ã‚’å®Ÿè¡Œä¸­ã§ã™...")
        elif st.session_state.error_message:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{st.session_state.error_message.splitlines()[0]}") # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸çŸ­ç¸®è¡¨ç¤º

        st.divider()
        # --- ãƒ‡ãƒãƒƒã‚°æƒ…å ±ãªã© ---
        if logger.level <= logging.DEBUG:
            st.sidebar.subheader("Debug Info")
            st.sidebar.write(f"Current Step: {st.session_state.current_step}")
            st.sidebar.write(f"Processing: {st.session_state.processing}")
            st.sidebar.write(f"M File: {st.session_state.moushikomi_file_name}")
            st.sidebar.write(f"E File: {st.session_state.estimate_csv_file_name}")
            st.sidebar.write(f"Store: {st.session_state.store_name}")
            # ä»–ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚‚å¿…è¦ãªã‚‰è¡¨ç¤º

    # === ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ===
    st.header("ğŸ“Š æ¤œè¨¼çµæœ")

    # --- ã‚¨ãƒ©ãƒ¼è¡¨ç¤º ---
    if st.session_state.error_message and not processing_now:
        st.error("å‰å›ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
            st.code(st.session_state.error_message, language=None)

    # --- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º ---
    current_step = st.session_state.current_step
    if current_step == 0 and not files_ready:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ç”³ã—é€ã‚Šæ›¸ã¨è¦‹ç©æ˜ç´°CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    elif current_step == 0 and files_ready:
         st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ãŒã§ãã¾ã—ãŸã€‚ã€Œã‚¹ãƒ†ãƒƒãƒ—1: èª­è¾¼ï¼†åŸºæœ¬æƒ…å ±æŠ½å‡ºã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    elif current_step == 1:
        st.success("ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨åŸºæœ¬æƒ…å ±æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        st.info("ã€Œã‚¹ãƒ†ãƒƒãƒ—2: ç”³é€/RAGæ•´åˆæ€§ç¢ºèªã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    elif current_step == 2:
         st.success("ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: ç”³ã—é€ã‚Šæ›¸ã¨æ¨™æº–ä»•æ§˜(RAG)ã®æ•´åˆæ€§ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
         st.info("ã€Œã‚¹ãƒ†ãƒƒãƒ—3: è¦‹ç©æ•´åˆæ€§ç¢ºèªã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    elif current_step == 3:
         st.success("ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: è¦‹ç©æ˜ç´°ã¨ä»•æ§˜ã®æ•´åˆæ€§ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
         st.info("æœ€çµ‚çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # --- çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢ ---
    if current_step > 0:
        tab_titles = [
            "â‘  åŸºæœ¬æƒ…å ±",
            f"â‘¡ ç”³é€/RAGæ¯”è¼ƒ ({len(st.session_state.comparison_discrepancies)})" if current_step >= 2 else "â‘¡ ç”³é€/RAGæ¯”è¼ƒ",
            f"â‘¢ è¦‹ç©ãƒã‚§ãƒƒã‚¯ ({len(st.session_state.detail_check_violations)})" if current_step >= 3 else "â‘¢ è¦‹ç©ãƒã‚§ãƒƒã‚¯",
            f"ğŸš¨ æœ€çµ‚å•é¡Œç‚¹" if current_step >= 3 else "ğŸš¨ å•é¡Œç‚¹ (å¾…æ©Ÿä¸­)",
        ]
        tab1, tab2, tab3, tab4 = st.tabs(tab_titles)

        with tab1: # åŸºæœ¬æƒ…å ± (ã‚¹ãƒ†ãƒƒãƒ—1ã®çµæœ)
            st.subheader("â‘  èª­ã¿è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã¨æŠ½å‡ºæƒ…å ±")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**ç”³ã—é€ã‚Šæ›¸:** `{st.session_state.moushikomi_file_name or 'N/A'}`")
                with st.expander("OCRãƒ†ã‚­ã‚¹ãƒˆ (æŠœç²‹)", expanded=False):
                    ocr = st.session_state.moushikomi_ocr_text or "(æœªå‡¦ç†)"
                    st.text_area("m_ocr_disp_tab1", format_document_snippet(ocr, 500), height=150, disabled=True)
                st.markdown(f"**æŠ½å‡ºã•ã‚ŒãŸå·¥å‹™åº—å:** `{st.session_state.store_name or '(æœªæŠ½å‡º)'}`")
                with st.expander("ç”³ã—é€ã‚Šæ›¸ã‹ã‚‰ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æŠ½å‡ºæƒ…å ±", expanded=False):
                    st.json(st.session_state.moushikomi_details or {})

            with col2:
                st.markdown(f"**è¦‹ç©æ˜ç´°CSV:** `{st.session_state.estimate_csv_file_name or 'N/A'}`")
                if st.session_state.estimate_dataframe is not None:
                    st.dataframe(st.session_state.estimate_dataframe.head(), height=250, use_container_width=True)
                    st.caption(f"å…¨{len(st.session_state.estimate_dataframe)}è¡Œ (å…ˆé ­5è¡Œè¡¨ç¤º)")
                else:
                    st.info("è¦‹ç©æ˜ç´°CSVã¯ã¾ã èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        with tab2: # ç”³é€/RAGæ¯”è¼ƒ (ã‚¹ãƒ†ãƒƒãƒ—2ã®çµæœ)
            st.subheader("â‘¡ ç”³ã—é€ã‚Šæ›¸ã¨RAGã«ã‚ˆã‚‹æ¨™æº–ä»•æ§˜ã®æ¯”è¼ƒ")
            if current_step < 2:
                st.info("ã‚¹ãƒ†ãƒƒãƒ—2ã‚’å®Œäº†ã™ã‚‹ã¨ã€ã“ã“ã«æ¯”è¼ƒçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            else:
                if st.session_state.comparison_discrepancies:
                    st.warning(f"{len(st.session_state.comparison_discrepancies)} ä»¶ã®ä¸ä¸€è‡´ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
                    for d in st.session_state.comparison_discrepancies:
                        st.markdown(f"- {d}")
                else:
                    st.success("ç”³ã—é€ã‚Šæ›¸ã®æƒ…å ±ã¨RAGã§ç¢ºèªã—ãŸæ¨™æº–ä»•æ§˜ã®é–“ã«ã€å®šç¾©ã•ã‚ŒãŸä¸ä¸€è‡´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

                with st.expander("RAGã«ã‚ˆã‚‹æ¨™æº–ä»•æ§˜ç¢ºèªçµæœ (è³ªå•ã¨å›ç­”)", expanded=False):
                    if st.session_state.rag_qa_results:
                        st.markdown(f"**å®Ÿè¡Œè³ªå•æ•°:** {len(st.session_state.rag_qa_results)}")
                        for i, result in enumerate(st.session_state.rag_qa_results):
                            q = result.get('q', 'è³ªå•ä¸æ˜')
                            answer = result.get('a', '[å›ç­”ãªã—]')
                            expanded_state = "[Error" in answer or "åˆ¤æ–­ã§ãã¾ã›ã‚“" in answer or "é–¢é€£æƒ…å ±ãªã—" in answer
                            with st.expander(f"Q{i+1}: {q}", expanded=expanded_state):
                                st.markdown("**å¤–éƒ¨DBå›ç­”:**")
                                if "[Error" in answer or "[RAG Error" in answer: st.error(answer)
                                elif "åˆ¤æ–­ã§ãã¾ã›ã‚“" in answer or "é–¢é€£æƒ…å ±ãªã—" in answer: st.warning(answer)
                                else: st.info(answer)
                                # å¿…è¦ãªã‚‰ã‚½ãƒ¼ã‚¹è¡¨ç¤ºã‚’è¿½åŠ 
                    elif st.session_state.store_name and st.session_state.store_name != "æŠ½å‡ºå¤±æ•—":
                         st.info("RAGã«ã‚ˆã‚‹ä»•æ§˜ç¢ºèªã¯å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    else:
                         st.info("å·¥å‹™åº—åä¸æ˜ç­‰ã®ãŸã‚ã€RAGã«ã‚ˆã‚‹ä»•æ§˜ç¢ºèªã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")

        with tab3: # è¦‹ç©ãƒã‚§ãƒƒã‚¯ (ã‚¹ãƒ†ãƒƒãƒ—3ã®çµæœ)
            st.subheader("â‘¢ è¦‹ç©æ˜ç´°ã¨ä»•æ§˜ï¼ˆç”³ã—é€ã‚Šæ›¸ï¼‹RAGï¼‰ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯")
            if current_step < 3:
                st.info("ã‚¹ãƒ†ãƒƒãƒ—3ã‚’å®Œäº†ã™ã‚‹ã¨ã€ã“ã“ã«ãƒã‚§ãƒƒã‚¯çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            else:
                if st.session_state.detail_check_violations:
                     st.warning(f"{len(st.session_state.detail_check_violations)} ä»¶ã®é•åã¾ãŸã¯ä¸æ•´åˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
                     for v in st.session_state.detail_check_violations[:50]: # è¡¨ç¤ºä»¶æ•°åˆ¶é™
                         st.markdown(f"- {v}")
                     if len(st.session_state.detail_check_violations) > 50:
                         st.caption("... (è¡¨ç¤ºä»¶æ•°ä¸Šé™)")
                else:
                     st.success("è¦‹ç©æ˜ç´°ã¨ä»•æ§˜ã®é–“ã«ã€å®šç¾©ã•ã‚ŒãŸé•åã‚„ä¸æ•´åˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

                with st.expander("ãƒã‚§ãƒƒã‚¯ã«ä½¿ç”¨ã—ãŸè¦‹ç©æ˜ç´°ãƒ‡ãƒ¼ã‚¿ (å…¨ä½“è¡¨ç¤º)", expanded=False):
                    if st.session_state.estimate_dataframe is not None:
                         st.dataframe(st.session_state.estimate_dataframe, height=300, use_container_width=True)
                    else:
                         st.info("è¦‹ç©æ˜ç´°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        with tab4: # æœ€çµ‚å•é¡Œç‚¹ (ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†å¾Œ)
            st.subheader("ğŸš¨ æœ€çµ‚çš„ãªå•é¡Œç‚¹ã®ã¾ã¨ã‚")
            if current_step < 3:
                st.info("ã‚¹ãƒ†ãƒƒãƒ—3ã¾ã§å®Œäº†ã™ã‚‹ã¨ã€ã“ã“ã«å•é¡Œç‚¹ã®æœ€çµ‚ãƒªã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            else:
                final_issue_list = []
                # ã‚¹ãƒ†ãƒƒãƒ—2ã¨3ã®çµæœã‚’çµåˆ
                if st.session_state.comparison_discrepancies:
                    final_issue_list.extend([f"[ç”³é€/RAGä¸ä¸€è‡´] {d}" for d in st.session_state.comparison_discrepancies])
                if st.session_state.detail_check_violations:
                    final_issue_list.extend([f"[æ˜ç´°/ä»•æ§˜ä¸ä¸€è‡´] {v}" for v in st.session_state.detail_check_violations])

                if final_issue_list:
                    st.warning(f"{len(final_issue_list)} ä»¶ã®å•é¡Œç‚¹ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚")
                    st.markdown("##### ç”³ã—é€ã‚Šæ›¸/RAGä¸ä¸€è‡´:")
                    compare_issues = [s for s in final_issue_list if s.startswith("[ç”³é€/RAGä¸ä¸€è‡´]")]
                    if compare_issues:
                        for issue in compare_issues: st.markdown(f"- {issue.replace('[ç”³é€/RAGä¸ä¸€è‡´] ','')}")
                    else: st.caption("ãªã—")

                    st.markdown("##### æ˜ç´°/ä»•æ§˜ä¸ä¸€è‡´:")
                    detail_issues = [s for s in final_issue_list if s.startswith("[æ˜ç´°/ä»•æ§˜ä¸ä¸€è‡´]")]
                    if detail_issues:
                        for issue in detail_issues: st.markdown(f"- {issue.replace('[æ˜ç´°/ä»•æ§˜ä¸ä¸€è‡´] ','')}")
                    else: st.caption("ãªã—")
                else:
                    st.success("å•é¡Œç‚¹ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    # Streamlitã® on_session_end ã¯ãªã„ã®ã§ã€ã“ã®ä½ç½®ã§æ¯å›ãƒã‚§ãƒƒã‚¯ã™ã‚‹ï¼ˆã‚„ã‚„éåŠ¹ç‡ï¼‰
    # ã¾ãŸã¯ã€ã‚ˆã‚Šé«˜åº¦ãªç®¡ç†ï¼ˆä¾‹: çµ‚äº†ãƒœã‚¿ãƒ³ã‚’è¨­ã‘ã‚‹ï¼‰ãŒå¿…è¦
    # cleanup_temp_files() # ã“ã“ã§å‘¼ã¶ã¨ rerun æ™‚ã«æ¶ˆãˆã¦ã—ã¾ã†å¯èƒ½æ€§

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ ---
if __name__ == "__main__":
    logger.info("Starting RAGapp_micheck (Step-by-Step version)...")
    main()
    # ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¯ Streamlit ã®æ¨™æº–æ©Ÿèƒ½ã§ã¯é›£ã—ã„
    # å¿…è¦ã§ã‚ã‚Œã°ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ã‚’æ¤œçŸ¥ã™ã‚‹ãƒãƒƒã‚¯ã‚„ã€
    # å®šæœŸçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ¤œè¨ã™ã‚‹ã€‚
    # logger.info("Application main function finished.")