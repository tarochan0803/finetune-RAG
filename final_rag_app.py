# final_rag_app.py - æœ€çµ‚ç‰ˆRAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ + æ—¢å­˜RAGã‚¤ãƒ³ãƒ•ãƒ© + æœ€é©åŒ– = å®Œå…¨ãªãƒ­ãƒ¼ã‚«ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ 

import os
import sys
import warnings
warnings.filterwarnings("ignore")

# PATHè¨­å®š
sys.path.append('/home/ncnadmin/.local/bin')
os.environ['PATH'] = '/home/ncnadmin/.local/bin:' + os.environ.get('PATH', '')

import streamlit as st
import pandas as pd
import time
import json
import torch
from typing import List, Dict, Any, Optional
from datetime import datetime

class FinalRAGSystem:
    """æœ€çµ‚ç‰ˆRAGã‚·ã‚¹ãƒ†ãƒ  - é«˜å“è³ªãƒ‡ãƒ¼ã‚¿æ´»ç”¨"""
    
    def __init__(self):
        self.premium_data = self.load_premium_data()
        self.company_data = self.organize_by_company()
        self.spec_categories = self.categorize_specs()
        
    def load_premium_data(self) -> List[Dict]:
        """é«˜å“è³ªæ‹¡å¼µãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            data = []
            with open("/home/ncnadmin/my_rag_project/premium_training_dataset.jsonl", 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        item = json.loads(line)
                        data.append(item)
            return data
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def organize_by_company(self) -> Dict[str, List[Dict]]:
        """å·¥å‹™åº—åˆ¥ãƒ‡ãƒ¼ã‚¿æ•´ç†"""
        companies = {}
        for item in self.premium_data:
            input_text = item.get('input', '')
            if 'æ ªå¼ä¼šç¤¾' in input_text:
                company = input_text.split('ä»£è¡¨æ¡ä»¶è¡¨')[0].strip()
                if company not in companies:
                    companies[company] = []
                companies[company].append(item)
        return companies
    
    def categorize_specs(self) -> Dict[str, List[Dict]]:
        """ä»•æ§˜ã‚«ãƒ†ã‚´ãƒªåˆ¥æ•´ç†"""
        categories = {
            'å£ä»•æ§˜': [],
            'è€åŠ›å£': [],
            'æ§‹é€ æ': [],
            'é‡‘ç‰©': [],
            'åŸºç¤': [],
            'å‰¯è³‡æ': [],
            'ãã®ä»–': []
        }
        
        for item in self.premium_data:
            input_text = item.get('input', '').lower()
            
            if 'å£é¢æä»•æ§˜' in input_text or 'å£ä»•æ§˜' in input_text:
                categories['å£ä»•æ§˜'].append(item)
            elif 'è€åŠ›å£' in input_text:
                categories['è€åŠ›å£'].append(item)
            elif 'åœŸå°' in input_text or 'æŸ±' in input_text or 'æ¨ªæ¶æ' in input_text:
                categories['æ§‹é€ æ'].append(item)
            elif 'é‡‘ç‰©' in input_text or 'ã‚¹ã‚¯ãƒªãƒ¥ãƒ¼' in input_text:
                categories['é‡‘ç‰©'].append(item)
            elif 'åŸºç¤' in input_text:
                categories['åŸºç¤'].append(item)
            elif 'é‹¼è£½æŸ' in input_text or 'ä»®ç­‹äº¤' in input_text:
                categories['å‰¯è³‡æ'].append(item)
            else:
                categories['ãã®ä»–'].append(item)
        
        return categories
    
    def smart_search(self, query: str, search_type: str = "general") -> List[Dict]:
        """ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢"""
        query_lower = query.lower()
        matches = []
        
        # æ¤œç´¢å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚’æ±ºå®š
        if search_type == "company" and 'æ ªå¼ä¼šç¤¾' in query:
            company_name = None
            for company in self.company_data.keys():
                if company in query:
                    company_name = company
                    break
            
            if company_name:
                search_data = self.company_data[company_name]
            else:
                search_data = self.premium_data
        elif search_type == "category":
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¤œç´¢
            category_data = []
            for category, items in self.spec_categories.items():
                if category.lower() in query_lower:
                    category_data.extend(items)
            search_data = category_data if category_data else self.premium_data
        else:
            search_data = self.premium_data
        
        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ¤œç´¢
        for item in search_data:
            input_text = item.get('input', '').lower()
            output_text = item.get('output', '').lower()
            instruction = item.get('instruction', '').lower()
            
            score = 0
            keywords = query_lower.split()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã‚¹ã‚³ã‚¢
            for keyword in keywords:
                if keyword in input_text:
                    score += 3  # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒã¯é«˜ã‚¹ã‚³ã‚¢
                if keyword in output_text:
                    score += 2  # å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒ
                if keyword in instruction:
                    score += 1  # æŒ‡ç¤ºãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒ
            
            # å®Œå…¨ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹
            if query_lower in input_text or query_lower in output_text:
                score += 5
            
            if score > 0:
                matches.append({
                    **item,
                    'search_score': score
                })
        
        # ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
        matches.sort(key=lambda x: x['search_score'], reverse=True)
        return matches[:10]  # ä¸Šä½10ä»¶
    
    def generate_enhanced_answer(self, query: str, matches: List[Dict]) -> str:
        """é«˜å“è³ªå›ç­”ç”Ÿæˆ"""
        if not matches:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã”è³ªå•ã«é–¢ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\nåˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãŠè©¦ã—ãã ã•ã„ã€‚"
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®å›ç­”ã‚’ãƒ™ãƒ¼ã‚¹ã«
        primary_answer = matches[0].get('output', '')
        
        # å·¥å‹™åº—åã®ç‰¹å®š
        company_mentioned = None
        for company in self.company_data.keys():
            if company in query or company in matches[0].get('input', ''):
                company_mentioned = company
                break
        
        # å›ç­”æ§‹ç¯‰
        answer_parts = []
        
        if company_mentioned:
            answer_parts.append(f"**{company_mentioned}** ã«ã¤ã„ã¦:")
        
        answer_parts.append(primary_answer)
        
        # é–¢é€£æƒ…å ±ã®è¿½åŠ 
        if len(matches) > 1:
            related_info = []
            for match in matches[1:4]:  # é–¢é€£æƒ…å ±3ä»¶ã¾ã§
                output = match.get('output', '').strip()
                if output and output != primary_answer and len(output) > 10:
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    if not any(output in existing for existing in related_info):
                        related_info.append(output)
            
            if related_info:
                answer_parts.append("\n**é–¢é€£æƒ…å ±:**")
                for info in related_info:
                    answer_parts.append(f"â€¢ {info}")
        
        return "\n".join(answer_parts)
    
    def query_rag(self, user_query: str) -> Dict[str, Any]:
        """RAGã‚¯ã‚¨ãƒªå®Ÿè¡Œ"""
        start_time = time.time()
        
        # æ¤œç´¢ã‚¿ã‚¤ãƒ—åˆ¤å®š
        search_type = "general"
        if 'æ ªå¼ä¼šç¤¾' in user_query:
            search_type = "company"
        elif any(cat in user_query.lower() for cat in ['å£', 'æ§‹é€ ', 'é‡‘ç‰©', 'åŸºç¤']):
            search_type = "category"
        
        # ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢å®Ÿè¡Œ
        matches = self.smart_search(user_query, search_type)
        
        # é«˜å“è³ªå›ç­”ç”Ÿæˆ
        answer = self.generate_enhanced_answer(user_query, matches)
        
        end_time = time.time()
        
        return {
            'answer': answer,
            'matches': matches,
            'search_type': search_type,
            'processing_time': end_time - start_time,
            'data_source': 'Premium Training Dataset (60,403 items)'
        }

def create_streamlit_app():
    """Streamlitã‚¢ãƒ—ãƒªä½œæˆ"""
    st.set_page_config(
        page_title="æœ€çµ‚ç‰ˆRAG", 
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸš€ æœ€çµ‚ç‰ˆRAGã‚·ã‚¹ãƒ†ãƒ ")
    st.caption("60,403ä»¶ã®é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ + æœ€é©åŒ–æ¤œç´¢ = å®Œå…¨ãªãƒ­ãƒ¼ã‚«ãƒ«RAG")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    @st.cache_resource
    def load_final_rag():
        return FinalRAGSystem()
    
    rag_system = load_final_rag()
    
    if not rag_system.premium_data:
        st.error("âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        st.stop()
    
    # ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    col1, col2 = st.columns([2, 1])
    
    with col2:
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
        st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        # çµ±è¨ˆæƒ…å ±
        total_data = len(rag_system.premium_data)
        companies = len(rag_system.company_data)
        
        st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•°", f"{total_data:,}ä»¶")
        st.metric("å¯¾å¿œå·¥å‹™åº—æ•°", f"{companies}ç¤¾")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ãƒ¼ã‚¿æ•°
        st.subheader("ğŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ãƒ¼ã‚¿")
        for category, items in rag_system.spec_categories.items():
            if items:
                st.write(f"â€¢ {category}: {len(items)}ä»¶")
        
        # å·¥å‹™åº—ãƒªã‚¹ãƒˆ
        st.subheader("ğŸ¢ å¯¾å¿œå·¥å‹™åº—")
        for company in list(rag_system.company_data.keys())[:10]:
            count = len(rag_system.company_data[company])
            st.write(f"â€¢ {company}: {count}ä»¶")
        
        if len(rag_system.company_data) > 10:
            st.write(f"... ä»–{len(rag_system.company_data) - 10}ç¤¾")
        
        # ã‚·ã‚¹ãƒ†ãƒ ç‰¹å¾´
        st.subheader("âœ¨ ã‚·ã‚¹ãƒ†ãƒ ç‰¹å¾´")
        st.success("âœ… 60,403ä»¶ã®é«˜å“è³ªãƒ‡ãƒ¼ã‚¿")
        st.success("âœ… ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ")
        st.success("âœ… å·¥å‹™åº—åˆ¥ç‰¹åŒ–æ¤œç´¢")
        st.success("âœ… ã‚«ãƒ†ã‚´ãƒªåˆ¥æ•´ç†")
        st.success("âœ… å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«å‹•ä½œ")
        st.success("âœ… APIã‚³ã‚¹ãƒˆã‚¼ãƒ­")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
        if torch.cuda.is_available():
            try:
                gpu_name = torch.cuda.get_device_name(0)
                st.info(f"ğŸ® GPU: {gpu_name}")
            except:
                st.info("ğŸ’» CPUå‹•ä½œ")
        else:
            st.info("ğŸ’» CPUå‹•ä½œ")
    
    with col1:
        # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆ
        st.header("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
        
        # ã‚µãƒ³ãƒ—ãƒ«è³ªå•
        st.subheader("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«è³ªå•")
        sample_cols = st.columns(3)
        
        sample_queries = [
            "æ ªå¼ä¼šç¤¾ä¸‰å»ºã®å£ä»•æ§˜ã«ã¤ã„ã¦",
            "æ ªå¼ä¼šç¤¾ãƒ‡ã‚¶ã‚ªå»ºè¨­ã®å£é¢æä»•æ§˜ã¯ï¼Ÿ",
            "ä»®ç­‹äº¤ã®æ¨™æº–ä»•æ§˜ã«ã¤ã„ã¦æ•™ãˆã¦",
            "é‹¼è£½æŸã®ä½¿ç”¨åŸºæº–ã¯ï¼Ÿ",
            "è€åŠ›å£ä»•æ§˜ã®1ç´š9ãœã«ã¤ã„ã¦",
            "åŸºç¤ã®ç«‹ä¸Šé«˜ã•ã®è¦å®šã¯ï¼Ÿ"
        ]
        
        for i, sample in enumerate(sample_queries):
            col = sample_cols[i % 3]
            if col.button(sample, key=f"sample_{i}"):
                st.session_state['sample_query'] = sample
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # ã‚µãƒ³ãƒ—ãƒ«è³ªå•å‡¦ç†
        if 'sample_query' in st.session_state:
            user_input = st.session_state['sample_query']
            del st.session_state['sample_query']
        else:
            user_input = None
        
        # ä¼šè©±å±¥æ­´è¡¨ç¤º
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
        
        # è³ªå•å…¥åŠ›
        if not user_input:
            user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")
        
        if user_input:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
            with st.chat_message("user"):
                st.markdown(user_input)
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # AIå¿œç­”
            with st.chat_message("assistant"):
                with st.spinner("ğŸ” æ¤œç´¢ãƒ»åˆ†æä¸­..."):
                    result = rag_system.query_rag(user_input)
                
                # å›ç­”è¡¨ç¤º
                st.markdown(result["answer"])
                
                # è©³ç´°æƒ…å ±
                with st.expander("ğŸ“Š æ¤œç´¢è©³ç´°æƒ…å ±"):
                    detail_cols = st.columns(4)
                    
                    with detail_cols[0]:
                        st.metric("å‡¦ç†æ™‚é–“", f"{result['processing_time']:.3f}ç§’")
                    with detail_cols[1]:
                        st.metric("ãƒãƒƒãƒæ•°", len(result['matches']))
                    with detail_cols[2]:
                        st.metric("æ¤œç´¢ã‚¿ã‚¤ãƒ—", result['search_type'])
                    with detail_cols[3]:
                        st.metric("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", "Premium")
                    
                    # ãƒãƒƒãƒã—ãŸæƒ…å ±ã®è¡¨ç¤º
                    if result['matches']:
                        st.subheader("ğŸ¯ ãƒãƒƒãƒã—ãŸæƒ…å ± (ä¸Šä½5ä»¶)")
                        for i, match in enumerate(result['matches'][:5]):
                            with st.expander(f"ãƒãƒƒãƒ {i+1} (ã‚¹ã‚³ã‚¢: {match.get('search_score', 0)})"):
                                st.text_area("è³ªå•/å…¥åŠ›", match.get('input', ''), height=80, disabled=True)
                                st.text_area("å›ç­”/å‡ºåŠ›", match.get('output', ''), height=80, disabled=True)
                                if match.get('instruction'):
                                    st.text_area("æŒ‡ç¤º", match.get('instruction', ''), height=60, disabled=True)
            
            st.session_state.messages.append({"role": "assistant", "content": result["answer"]})
        
        # çµ±è¨ˆè¡¨ç¤º
        if st.session_state.messages:
            st.subheader("ğŸ“ˆ ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
            user_messages = [m for m in st.session_state.messages if m["role"] == "user"]
            st.metric("è³ªå•æ•°", len(user_messages))
            st.metric("ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ç‡", f"{total_data:,}ä»¶æ´»ç”¨ä¸­")

def main():
    create_streamlit_app()

if __name__ == "__main__":
    main()