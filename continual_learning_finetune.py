#!/usr/bin/env python3
# continual_learning_finetune.py - ç¶™ç¶šå­¦ç¿’å¯¾å¿œãƒ•ãƒ«ã‚¹ãƒšãƒƒã‚¯ç‰ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
"""
ç¶™ç¶šå­¦ç¿’ï¼ˆContinual Learningï¼‰å¯¾å¿œã®é«˜åº¦ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
- æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®ç¶™ç¶šå­¦ç¿’
- çŸ¥è­˜ã®å¿˜å´ã‚’é˜²ãRegularizationæŠ€è¡“
- Elastic Weight Consolidation (EWC)
- æ®µéšçš„ãªã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’
- è¤‡æ•°ã‚¿ã‚¹ã‚¯ã®å­¦ç¿’å±¥æ­´ç®¡ç†
"""

import os
import sys
import json
import logging
import shutil
import pickle
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, asdict
import copy

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
from datasets import load_dataset, Dataset, concatenate_datasets
from transformers import (
    AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments,
    DataCollatorForSeq2Seq, EarlyStoppingCallback, TrainerCallback
)
from peft import LoraConfig, get_peft_model, TaskType, PeftModel
import wandb

@dataclass
class ContinualLearningConfig:
    """ç¶™ç¶šå­¦ç¿’è¨­å®š"""
    # åŸºæœ¬è¨­å®š
    base_model_path: str = "./full_spec_rag_model"  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    checkpoint_interval: int = 500  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜é–“éš”
    
    # EWC (Elastic Weight Consolidation) è¨­å®š
    use_ewc: bool = True
    ewc_lambda: float = 1000.0  # EWCæ­£å‰‡åŒ–å¼·åº¦
    fisher_estimation_sample_size: int = 1000  # Fisheræƒ…å ±è¡Œåˆ—æ¨å®šã‚µãƒ³ãƒ—ãƒ«æ•°
    
    # å­¦ç¿’ç‡èª¿æ•´
    initial_lr_factor: float = 0.1  # ç¶™ç¶šå­¦ç¿’æ™‚ã®åˆæœŸå­¦ç¿’ç‡å€ç‡
    lr_decay_factor: float = 0.9   # å„ã‚¿ã‚¹ã‚¯ã§ã®å­¦ç¿’ç‡æ¸›è¡°
    
    # ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’è¨­å®š
    use_curriculum: bool = True
    difficulty_threshold: float = 0.8  # é›£æ˜“åº¦é–¾å€¤
    curriculum_batch_size_factor: float = 0.5  # ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºå€ç‡
    
    # çŸ¥è­˜è’¸ç•™è¨­å®š
    use_knowledge_distillation: bool = True
    kd_temperature: float = 4.0     # è’¸ç•™æ¸©åº¦
    kd_alpha: float = 0.7          # è’¸ç•™æå¤±ã®é‡ã¿
    
    # ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡è¨­å®š
    use_replay_buffer: bool = True
    replay_buffer_size: int = 10000  # ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
    replay_sample_rate: float = 0.2  # ãƒªãƒ—ãƒ¬ã‚¤ã‚µãƒ³ãƒ—ãƒ«ã®å‰²åˆ
    
    # ã‚¿ã‚¹ã‚¯ç®¡ç†
    max_tasks: int = 10  # æœ€å¤§ã‚¿ã‚¹ã‚¯æ•°
    task_memory_size: int = 5000  # ã‚¿ã‚¹ã‚¯ã”ã¨ã®ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚º

@dataclass
class TaskInfo:
    """ã‚¿ã‚¹ã‚¯æƒ…å ±"""
    task_id: str
    name: str
    description: str
    data_path: str
    model_path: str
    timestamp: str
    performance_metrics: Dict[str, float]
    fisher_diagonal: Optional[Dict[str, torch.Tensor]] = None
    optimal_params: Optional[Dict[str, torch.Tensor]] = None

class FisherInformationMatrix:
    """Fisheræƒ…å ±è¡Œåˆ—è¨ˆç®—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model: nn.Module, dataloader: DataLoader, device: str = "cuda"):
        self.model = model
        self.dataloader = dataloader
        self.device = device
        
    def compute_fisher_diagonal(self, sample_size: int = 1000) -> Dict[str, torch.Tensor]:
        """Fisheræƒ…å ±è¡Œåˆ—ã®å¯¾è§’æˆåˆ†ã‚’è¨ˆç®—"""
        fisher_diagonal = {}
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’evalæ¨¡ãƒ¼ãƒ‰ã«
        self.model.eval()
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆæœŸåŒ–
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                fisher_diagonal[name] = torch.zeros_like(param)
        
        sample_count = 0
        for batch in self.dataloader:
            if sample_count >= sample_size:
                break
                
            batch = {k: v.to(self.device) for k, v in batch.items()}
            
            # å‹¾é…ã‚’ã‚¯ãƒªã‚¢
            self.model.zero_grad()
            
            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
            outputs = self.model(**batch)
            loss = outputs.loss
            
            # ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰
            loss.backward()
            
            # Fisheræƒ…å ±è¡Œåˆ—æ›´æ–°
            for name, param in self.model.named_parameters():
                if param.grad is not None and param.requires_grad:
                    fisher_diagonal[name] += param.grad.pow(2)
            
            sample_count += batch['input_ids'].size(0)
        
        # å¹³å‡åŒ–
        for name in fisher_diagonal:
            fisher_diagonal[name] /= sample_count
            
        return fisher_diagonal

class EWCLoss:
    """Elastic Weight Consolidationæå¤±"""
    
    def __init__(self, fisher_diagonal: Dict[str, torch.Tensor], 
                 optimal_params: Dict[str, torch.Tensor], ewc_lambda: float = 1000.0):
        self.fisher_diagonal = fisher_diagonal
        self.optimal_params = optimal_params
        self.ewc_lambda = ewc_lambda
    
    def compute_penalty(self, model: nn.Module) -> torch.Tensor:
        """EWCæ­£å‰‡åŒ–é …ã‚’è¨ˆç®—"""
        penalty = 0.0
        
        for name, param in model.named_parameters():
            if name in self.fisher_diagonal and param.requires_grad:
                penalty += (self.fisher_diagonal[name] * 
                           (param - self.optimal_params[name]).pow(2)).sum()
        
        return self.ewc_lambda * penalty

class ReplayBuffer:
    """çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self.buffer = []
        self.position = 0
    
    def add(self, experiences: List[Dict]):
        """çµŒé¨“ã‚’è¿½åŠ """
        for exp in experiences:
            if len(self.buffer) < self.max_size:
                self.buffer.append(exp)
            else:
                self.buffer[self.position] = exp
                self.position = (self.position + 1) % self.max_size
    
    def sample(self, batch_size: int) -> List[Dict]:
        """ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        if len(self.buffer) < batch_size:
            return self.buffer.copy()
        return np.random.choice(self.buffer, batch_size, replace=False).tolist()
    
    def size(self) -> int:
        return len(self.buffer)

class ContinualLearningTrainer(Trainer):
    """ç¶™ç¶šå­¦ç¿’å¯¾å¿œãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼"""
    
    def __init__(self, cl_config: ContinualLearningConfig, ewc_loss: Optional[EWCLoss] = None,
                 replay_buffer: Optional[ReplayBuffer] = None, teacher_model: Optional[nn.Module] = None, **kwargs):
        super().__init__(**kwargs)
        self.cl_config = cl_config
        self.ewc_loss = ewc_loss
        self.replay_buffer = replay_buffer
        self.teacher_model = teacher_model
        
    def compute_loss(self, model, inputs, return_outputs=False):
        """æ‹¡å¼µæå¤±é–¢æ•°"""
        # é€šå¸¸ã®æå¤±è¨ˆç®—
        outputs = model(**inputs)
        loss = outputs.loss
        
        # EWCæ­£å‰‡åŒ–é …
        if self.ewc_loss is not None:
            ewc_penalty = self.ewc_loss.compute_penalty(model)
            loss += ewc_penalty
        
        # çŸ¥è­˜è’¸ç•™æå¤±
        if self.teacher_model is not None and self.cl_config.use_knowledge_distillation:
            with torch.no_grad():
                teacher_outputs = self.teacher_model(**inputs)
            
            student_logits = outputs.logits
            teacher_logits = teacher_outputs.logits
            
            # è’¸ç•™æå¤±è¨ˆç®—
            kd_loss = self._compute_kd_loss(student_logits, teacher_logits, 
                                          self.cl_config.kd_temperature)
            loss = self.cl_config.kd_alpha * kd_loss + (1 - self.cl_config.kd_alpha) * loss
        
        return (loss, outputs) if return_outputs else loss
    
    def _compute_kd_loss(self, student_logits: torch.Tensor, teacher_logits: torch.Tensor, 
                        temperature: float) -> torch.Tensor:
        """çŸ¥è­˜è’¸ç•™æå¤±è¨ˆç®—"""
        student_probs = F.log_softmax(student_logits / temperature, dim=-1)
        teacher_probs = F.softmax(teacher_logits / temperature, dim=-1)
        return F.kl_div(student_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)

class ContinualLearningFineTuner:
    """ç¶™ç¶šå­¦ç¿’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒŠãƒ¼"""
    
    def __init__(self, base_config_path: Optional[str] = None):
        self.setup_logging()
        
        # è¨­å®šèª­ã¿è¾¼ã¿
        self.cl_config = ContinualLearningConfig()
        if base_config_path:
            self.load_base_config(base_config_path)
            
        # ç¶™ç¶šå­¦ç¿’è¨­å®šã‚’æ—¢å­˜è¨­å®šã«çµ±åˆ
        from full_spec_finetune import FullSpecFineTuner
        self.base_tuner = FullSpecFineTuner(base_config_path)
        
        # çŠ¶æ…‹ç®¡ç†
        self.task_history: List[TaskInfo] = []
        self.current_task_id = 0
        self.replay_buffer = ReplayBuffer(self.cl_config.replay_buffer_size) if self.cl_config.use_replay_buffer else None
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.setup_directories()
        
        self.logger.info("ğŸ”„ ç¶™ç¶šå­¦ç¿’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åˆæœŸåŒ–å®Œäº†")
    
    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler(f'continual_learning_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_base_config(self, config_path: str):
        """æ—¢å­˜è¨­å®šèª­ã¿è¾¼ã¿"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ç¶™ç¶šå­¦ç¿’è¨­å®šæ›´æ–°
        if 'continual_learning' in config:
            cl_config_dict = config['continual_learning']
            for key, value in cl_config_dict.items():
                if hasattr(self.cl_config, key):
                    setattr(self.cl_config, key, value)
    
    def setup_directories(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ"""
        dirs = [
            "continual_learning_checkpoints",
            "continual_learning_logs", 
            "task_history",
            "fisher_matrices",
            "replay_buffers"
        ]
        for dir_path in dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def load_previous_model(self) -> Tuple[AutoModelForCausalLM, AutoTokenizer]:
        """å‰å›ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        self.logger.info(f"ğŸ“‚ å‰å›ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {self.cl_config.base_model_path}")
        
        try:
            tokenizer = AutoTokenizer.from_pretrained(self.cl_config.base_model_path, trust_remote_code=True)
            model = AutoModelForCausalLM.from_pretrained(
                self.cl_config.base_model_path,
                torch_dtype=torch.bfloat16,
                device_map="auto",
                trust_remote_code=True
            )
            
            self.logger.info("âœ… å‰å›ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            return model, tokenizer
        except Exception as e:
            self.logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def compute_fisher_information(self, model: nn.Module, dataset: Dataset, 
                                 tokenizer: AutoTokenizer) -> Dict[str, torch.Tensor]:
        """Fisheræƒ…å ±è¡Œåˆ—è¨ˆç®—"""
        self.logger.info("ğŸ§® Fisheræƒ…å ±è¡Œåˆ—è¨ˆç®—é–‹å§‹")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼
        data_collator = DataCollatorForSeq2Seq(
            tokenizer=tokenizer,
            padding="longest",
            label_pad_token_id=-100,
        )
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        dataloader = DataLoader(
            dataset.select(range(min(self.cl_config.fisher_estimation_sample_size, len(dataset)))),
            batch_size=1,
            collate_fn=data_collator
        )
        
        # Fisheræƒ…å ±è¡Œåˆ—è¨ˆç®—
        fisher_computer = FisherInformationMatrix(model, dataloader)
        fisher_diagonal = fisher_computer.compute_fisher_diagonal(self.cl_config.fisher_estimation_sample_size)
        
        self.logger.info("âœ… Fisheræƒ…å ±è¡Œåˆ—è¨ˆç®—å®Œäº†")
        return fisher_diagonal
    
    def save_task_info(self, task_info: TaskInfo):
        """ã‚¿ã‚¹ã‚¯æƒ…å ±ä¿å­˜"""
        # Fisherè¡Œåˆ—ä¿å­˜
        if task_info.fisher_diagonal:
            fisher_path = f"fisher_matrices/fisher_{task_info.task_id}.pkl"
            with open(fisher_path, 'wb') as f:
                pickle.dump(task_info.fisher_diagonal, f)
        
        # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
        if task_info.optimal_params:
            params_path = f"fisher_matrices/params_{task_info.task_id}.pkl"
            with open(params_path, 'wb') as f:
                pickle.dump(task_info.optimal_params, f)
        
        # ã‚¿ã‚¹ã‚¯å±¥æ­´ä¿å­˜
        task_info_path = f"task_history/task_{task_info.task_id}.json"
        with open(task_info_path, 'w', encoding='utf-8') as f:
            task_data = asdict(task_info)
            # ãƒ†ãƒ³ã‚½ãƒ«ã¯é™¤å¤–
            task_data.pop('fisher_diagonal', None)
            task_data.pop('optimal_params', None)
            json.dump(task_data, f, indent=2, ensure_ascii=False)
    
    def load_task_history(self):
        """ã‚¿ã‚¹ã‚¯å±¥æ­´èª­ã¿è¾¼ã¿"""
        task_history_files = list(Path("task_history").glob("task_*.json"))
        
        for file_path in sorted(task_history_files):
            with open(file_path, 'r', encoding='utf-8') as f:
                task_data = json.load(f)
                task_info = TaskInfo(**task_data)
                
                # Fisherè¡Œåˆ—èª­ã¿è¾¼ã¿
                fisher_path = f"fisher_matrices/fisher_{task_info.task_id}.pkl"
                if os.path.exists(fisher_path):
                    with open(fisher_path, 'rb') as f:
                        task_info.fisher_diagonal = pickle.load(f)
                
                # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                params_path = f"fisher_matrices/params_{task_info.task_id}.pkl"
                if os.path.exists(params_path):
                    with open(params_path, 'rb') as f:
                        task_info.optimal_params = pickle.load(f)
                
                self.task_history.append(task_info)
        
        if self.task_history:
            self.current_task_id = max(int(task.task_id) for task in self.task_history) + 1
            self.logger.info(f"ğŸ“š ã‚¿ã‚¹ã‚¯å±¥æ­´èª­ã¿è¾¼ã¿å®Œäº†: {len(self.task_history)}ã‚¿ã‚¹ã‚¯")
    
    def prepare_curriculum_data(self, dataset: Dataset, tokenizer: AutoTokenizer) -> Dataset:
        """ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        if not self.cl_config.use_curriculum:
            return dataset
        
        self.logger.info("ğŸ“ˆ ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™")
        
        # é›£æ˜“åº¦æ¨å®šï¼ˆæ–‡ç« é•·ãƒ™ãƒ¼ã‚¹ï¼‰
        def estimate_difficulty(example):
            text_length = len(example.get('input', '') + example.get('output', ''))
            return min(text_length / 1000, 1.0)  # æ­£è¦åŒ–
        
        # é›£æ˜“åº¦è¿½åŠ 
        dataset = dataset.map(lambda x: {**x, 'difficulty': estimate_difficulty(x)})
        
        # é›£æ˜“åº¦ã§ã‚½ãƒ¼ãƒˆ
        dataset = dataset.sort('difficulty')
        
        # æ®µéšçš„ãªé›£æ˜“åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        easy_size = int(len(dataset) * 0.3)
        medium_size = int(len(dataset) * 0.6)
        
        curriculum_stages = [
            dataset.select(range(easy_size)),                    # Easy
            dataset.select(range(easy_size, medium_size)),       # Medium  
            dataset.select(range(medium_size, len(dataset)))     # Hard
        ]
        
        self.logger.info(f"   æ®µéš1 (ç°¡å˜): {len(curriculum_stages[0]):,}ä»¶")
        self.logger.info(f"   æ®µéš2 (ä¸­ç¨‹åº¦): {len(curriculum_stages[1]):,}ä»¶") 
        self.logger.info(f"   æ®µéš3 (å›°é›£): {len(curriculum_stages[2]):,}ä»¶")
        
        return curriculum_stages
    
    def add_new_task(self, task_name: str, data_path: str, description: str = "") -> str:
        """æ–°ã—ã„ã‚¿ã‚¹ã‚¯è¿½åŠ """
        task_id = str(self.current_task_id)
        self.current_task_id += 1
        
        self.logger.info(f"ğŸ“ æ–°ã‚¿ã‚¹ã‚¯è¿½åŠ : {task_name} (ID: {task_id})")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
        dataset = self.base_tuner.load_and_prepare_data()
        
        # å‰å›ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model, tokenizer = self.load_previous_model()
        
        # Teacher modelï¼ˆçŸ¥è­˜è’¸ç•™ç”¨ï¼‰
        teacher_model = None
        if self.cl_config.use_knowledge_distillation and self.task_history:
            teacher_model = copy.deepcopy(model)
            teacher_model.eval()
        
        # Fisheræƒ…å ±è¡Œåˆ—è¨ˆç®—ï¼ˆå‰ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã«ï¼‰
        fisher_diagonal = None
        optimal_params = None
        
        if self.cl_config.use_ewc and self.task_history:
            fisher_diagonal = self.compute_fisher_information(model, dataset['train'], tokenizer)
            optimal_params = {name: param.clone().detach() 
                            for name, param in model.named_parameters() if param.requires_grad}
        
        # EWCæå¤±æº–å‚™
        ewc_loss = None
        if self.task_history and self.cl_config.use_ewc:
            # å…¨ã¦ã®éå»ã‚¿ã‚¹ã‚¯ã®EWCæå¤±ã‚’çµ±åˆ
            combined_fisher = {}
            combined_params = {}
            
            for prev_task in self.task_history:
                if prev_task.fisher_diagonal and prev_task.optimal_params:
                    for name in prev_task.fisher_diagonal:
                        if name not in combined_fisher:
                            combined_fisher[name] = prev_task.fisher_diagonal[name].clone()
                            combined_params[name] = prev_task.optimal_params[name].clone()
                        else:
                            combined_fisher[name] += prev_task.fisher_diagonal[name]
            
            if combined_fisher:
                ewc_loss = EWCLoss(combined_fisher, combined_params, self.cl_config.ewc_lambda)
        
        # ãƒªãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿æº–å‚™
        replay_data = None
        if self.replay_buffer and self.replay_buffer.size() > 0:
            replay_samples = self.replay_buffer.sample(
                int(len(dataset['train']) * self.cl_config.replay_sample_rate)
            )
            replay_data = Dataset.from_list(replay_samples)
            dataset['train'] = concatenate_datasets([dataset['train'], replay_data])
            self.logger.info(f"   ãƒªãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿è¿½åŠ : {len(replay_samples):,}ä»¶")
        
        # ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’è¨­å®š
        training_stages = self.prepare_curriculum_data(dataset['train'], tokenizer) if self.cl_config.use_curriculum else [dataset['train']]
        
        # å„æ®µéšã§å­¦ç¿’å®Ÿè¡Œ
        for stage_idx, stage_dataset in enumerate(training_stages):
            self.logger.info(f"ğŸ¯ å­¦ç¿’æ®µéš {stage_idx + 1}/{len(training_stages)} é–‹å§‹")
            
            # å­¦ç¿’ç‡èª¿æ•´
            current_lr = (self.base_tuner.config['learning_rate'] * 
                         self.cl_config.initial_lr_factor * 
                         (self.cl_config.lr_decay_factor ** len(self.task_history)))
            
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´
            batch_size = self.base_tuner.config['per_device_train_batch_size']
            if self.cl_config.use_curriculum and stage_idx == 0:
                batch_size = max(1, int(batch_size * self.cl_config.curriculum_batch_size_factor))
            
            # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼è¨­å®š
            training_args = TrainingArguments(
                output_dir=f"continual_learning_checkpoints/task_{task_id}_stage_{stage_idx}",
                num_train_epochs=1 if self.cl_config.use_curriculum else 3,
                per_device_train_batch_size=batch_size,
                per_device_eval_batch_size=batch_size,
                learning_rate=current_lr,
                warmup_ratio=0.1,
                save_steps=self.cl_config.checkpoint_interval,
                evaluation_strategy="steps",
                eval_steps=self.cl_config.checkpoint_interval,
                logging_steps=50,
                save_total_limit=2,
                load_best_model_at_end=True,
                dataloader_num_workers=4,
                bf16=True,
                remove_unused_columns=False,
                report_to=["wandb"] if self.base_tuner.config.get('use_wandb', False) else [],
            )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼
            data_collator = DataCollatorForSeq2Seq(
                tokenizer=tokenizer,
                padding="longest",
                label_pad_token_id=-100,
            )
            
            # ç¶™ç¶šå­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
            trainer = ContinualLearningTrainer(
                cl_config=self.cl_config,
                ewc_loss=ewc_loss,
                replay_buffer=self.replay_buffer,
                teacher_model=teacher_model,
                model=model,
                args=training_args,
                train_dataset=stage_dataset,
                eval_dataset=dataset['eval'],
                data_collator=data_collator,
                tokenizer=tokenizer,
            )
            
            # å­¦ç¿’å®Ÿè¡Œ
            trainer.train()
            
            self.logger.info(f"âœ… å­¦ç¿’æ®µéš {stage_idx + 1} å®Œäº†")
        
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        final_model_path = f"continual_learning_checkpoints/task_{task_id}_final"
        trainer.save_model(final_model_path)
        tokenizer.save_pretrained(final_model_path)
        
        # ã‚¿ã‚¹ã‚¯æƒ…å ±ä½œæˆ
        task_info = TaskInfo(
            task_id=task_id,
            name=task_name,
            description=description,
            data_path=data_path,
            model_path=final_model_path,
            timestamp=datetime.now().isoformat(),
            performance_metrics={"final_loss": trainer.state.log_history[-1].get('eval_loss', 0.0)},
            fisher_diagonal=fisher_diagonal,
            optimal_params=optimal_params
        )
        
        # ã‚¿ã‚¹ã‚¯å±¥æ­´ã«è¿½åŠ 
        self.task_history.append(task_info)
        self.save_task_info(task_info)
        
        # ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡æ›´æ–°
        if self.replay_buffer:
            # ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ 
            task_samples = dataset['train'].select(range(min(1000, len(dataset['train']))))
            task_sample_list = [task_samples[i] for i in range(len(task_samples))]
            self.replay_buffer.add(task_sample_list)
            
            # ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ä¿å­˜
            with open(f"replay_buffers/buffer_after_task_{task_id}.pkl", 'wb') as f:
                pickle.dump(self.replay_buffer, f)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹æ›´æ–°
        self.cl_config.base_model_path = final_model_path
        
        self.logger.info(f"ğŸ‰ ã‚¿ã‚¹ã‚¯ {task_name} å®Œäº†")
        self.logger.info(f"   ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {final_model_path}")
        
        return task_id
    
    def evaluate_all_tasks(self) -> Dict[str, Dict[str, float]]:
        """å…¨ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½è©•ä¾¡"""
        self.logger.info("ğŸ“Š å…¨ã‚¿ã‚¹ã‚¯æ€§èƒ½è©•ä¾¡é–‹å§‹")
        
        if not self.task_history:
            self.logger.warning("è©•ä¾¡å¯¾è±¡ã®ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
            return {}
        
        # æœ€æ–°ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        latest_task = self.task_history[-1]
        model, tokenizer = self.load_previous_model()
        
        results = {}
        
        for task_info in self.task_history:
            self.logger.info(f"   ã‚¿ã‚¹ã‚¯ {task_info.name} è©•ä¾¡ä¸­...")
            
            try:
                # ã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                dataset = load_dataset("json", data_files={"test": task_info.data_path}, split="test")
                
                # ç°¡æ˜“è©•ä¾¡ï¼ˆå›°æƒ‘åº¦è¨ˆç®—ï¼‰
                # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè©³ç´°ãªè©•ä¾¡æŒ‡æ¨™ã‚’ä½¿ç”¨
                perplexity = self._compute_perplexity(model, dataset, tokenizer)
                
                results[task_info.task_id] = {
                    "task_name": task_info.name,
                    "perplexity": perplexity,
                    "timestamp": task_info.timestamp
                }
                
            except Exception as e:
                self.logger.error(f"ã‚¿ã‚¹ã‚¯ {task_info.name} è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                results[task_info.task_id] = {"error": str(e)}
        
        self.logger.info("âœ… å…¨ã‚¿ã‚¹ã‚¯æ€§èƒ½è©•ä¾¡å®Œäº†")
        return results
    
    def _compute_perplexity(self, model: nn.Module, dataset: Dataset, 
                          tokenizer: AutoTokenizer, max_samples: int = 100) -> float:
        """å›°æƒ‘åº¦è¨ˆç®—"""
        model.eval()
        total_loss = 0.0
        total_tokens = 0
        
        with torch.no_grad():
            for i, example in enumerate(dataset.select(range(min(max_samples, len(dataset))))):
                text = example.get('input', '') + example.get('output', '')
                
                inputs = tokenizer(text, return_tensors="pt", max_length=512, truncation=True)
                inputs = {k: v.to(model.device) for k, v in inputs.items()}
                
                outputs = model(**inputs, labels=inputs['input_ids'])
                loss = outputs.loss
                
                total_loss += loss.item() * inputs['input_ids'].size(1)
                total_tokens += inputs['input_ids'].size(1)
        
        return torch.exp(torch.tensor(total_loss / total_tokens)).item()
    
    def generate_task_report(self) -> str:
        """ã‚¿ã‚¹ã‚¯ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.task_history:
            return "ã‚¿ã‚¹ã‚¯å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        report = f"""
# ç¶™ç¶šå­¦ç¿’ã‚¿ã‚¹ã‚¯ãƒ¬ãƒãƒ¼ãƒˆ
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¦‚è¦
- ç·ã‚¿ã‚¹ã‚¯æ•°: {len(self.task_history)}
- ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ID: {self.current_task_id - 1}
- ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {self.replay_buffer.size() if self.replay_buffer else 0}

## ã‚¿ã‚¹ã‚¯å±¥æ­´
"""
        
        for i, task in enumerate(self.task_history, 1):
            report += f"""
### ã‚¿ã‚¹ã‚¯ {i}: {task.name}
- ID: {task.task_id}
- èª¬æ˜: {task.description}
- å­¦ç¿’æ—¥æ™‚: {task.timestamp}
- ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {task.model_path}
- æœ€çµ‚æå¤±: {task.performance_metrics.get('final_loss', 'N/A')}
"""
        
        # æ€§èƒ½è©•ä¾¡çµæœ
        evaluation_results = self.evaluate_all_tasks()
        if evaluation_results:
            report += "\n## æ€§èƒ½è©•ä¾¡çµæœ\n"
            for task_id, metrics in evaluation_results.items():
                if 'error' not in metrics:
                    report += f"- {metrics['task_name']}: å›°æƒ‘åº¦ {metrics['perplexity']:.2f}\n"
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç¶™ç¶šå­¦ç¿’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    parser.add_argument("--base-config", type=str, help="ãƒ™ãƒ¼ã‚¹è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--task-name", type=str, required=True, help="ã‚¿ã‚¹ã‚¯å")
    parser.add_argument("--data-path", type=str, required=True, help="ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹")
    parser.add_argument("--description", type=str, default="", help="ã‚¿ã‚¹ã‚¯èª¬æ˜")
    parser.add_argument("--evaluate", action="store_true", help="è©•ä¾¡ã®ã¿å®Ÿè¡Œ")
    parser.add_argument("--report", action="store_true", help="ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    
    args = parser.parse_args()
    
    print("ğŸ”„ ç¶™ç¶šå­¦ç¿’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    print("=" * 60)
    
    # ç¶™ç¶šå­¦ç¿’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
    tuner = ContinualLearningFineTuner(args.base_config)
    
    # ã‚¿ã‚¹ã‚¯å±¥æ­´èª­ã¿è¾¼ã¿
    tuner.load_task_history()
    
    if args.evaluate:
        # è©•ä¾¡ã®ã¿
        results = tuner.evaluate_all_tasks()
        print("\nğŸ“Š è©•ä¾¡çµæœ:")
        for task_id, metrics in results.items():
            if 'error' not in metrics:
                print(f"  {metrics['task_name']}: å›°æƒ‘åº¦ {metrics['perplexity']:.2f}")
    
    elif args.report:
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = tuner.generate_task_report()
        report_path = f"continual_learning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
    
    else:
        # æ–°ã‚¿ã‚¹ã‚¯è¿½åŠ 
        task_id = tuner.add_new_task(args.task_name, args.data_path, args.description)
        
        print(f"\nğŸ‰ ç¶™ç¶šå­¦ç¿’å®Œäº†ï¼")
        print(f"ã‚¿ã‚¹ã‚¯ID: {task_id}")
        print(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: continual_learning_checkpoints/task_{task_id}_final")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. æ€§èƒ½è©•ä¾¡: python continual_learning_finetune.py --evaluate")
        print("2. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: python continual_learning_finetune.py --report")

if __name__ == "__main__":
    main()